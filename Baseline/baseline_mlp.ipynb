{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12d1d89c",
   "metadata": {},
   "source": [
    "# Multilayer Perceptron baseline\n",
    "## Finally, it worked! Breadth > Depth\n",
    "\n",
    "The cell outputs in this notebook may not be up-to-date because training is usually done without manual oversight by exporting the notebook as a script.\n",
    "\n",
    "#### Regressor\n",
    "\n",
    "hidden_layer_sizes=(2048, 1024, 256): f1-score \\[0.46135 0.40327 0.12554 0.14801\\] avg 0.28454\n",
    "\n",
    "hidden_layer_sizes=(3072, 1024, 256): f1-score \\[0.64766 0.63497 0.52672 0.36453\\] avg **0.54347** (alt. run 0.26181)\n",
    "\n",
    "hidden_layer_sizes=(4096, 1024, 256): f1-score \\[0.58944 0.59615 0.46914 0.33229\\] avg 0.49676\n",
    "\n",
    "#### Classifier\n",
    "\n",
    "hidden_layer_sizes=(2048, 1024, 256): fl-score \\[0.67788 0.65749 0.47664 0.56250\\] avg 0.59363\n",
    "\n",
    "hidden_layer_sizes=(3072, 1024, 256): f1-score \\[0.56571 0.56881 0.45669 0.41216\\] avg 0.50084 (alt. run 0.64848)\n",
    "\n",
    "hidden_layer_sizes=(3072, 1024, 1024, 256): f1-score \\[0.69906 0.68421 0.54545 0.57143\\] avg 0.62504\n",
    "\n",
    "hidden_layer_sizes=(3072, 1024, 1024, 512, 256): f1-score \\[0.77641 0.79132 0.60000 0.60976\\] avg **0.69437**\n",
    "\n",
    "hidden_layer_sizes=(4096, 1024, 256): f1-score \\[0.62189 0.59155 0.46945 0.32911\\] avg 0.50300\n",
    "\n",
    "\n",
    "### Switched to TSNV\n",
    "\n",
    "hidden_layer_sizes=(2816, 1024, 1024, 1024, 256): f1-score \\[0.79548 0.81391 0.73973 0.72603\\] average 0.76879\n",
    "\n",
    "hidden_layer_sizes=(3072, 1024, 1024, 1024, 256): f1-score \\[0.82739 0.87162 0.78970 0.77660\\] average **0.81633** (alt. run 0.82256, alpha=0.01 => 0.82789)\n",
    "\n",
    "hidden_layer_sizes=(3072, 1024, 1024, 1024): f1-score \\[0.80282 0.81685 0.78571 0.76510\\] average 0.79262\n",
    "\n",
    "hidden_layer_sizes=(3072, 1024, 1024, 256): f1-score \\[0.83931 0.84069 0.79808 0.76923\\] average 0.81183 (alt. run 81299)\n",
    "\n",
    "hidden_layer_sizes=(3072, 1024, 1024): f1-score \\[0.65041 0.60197 0.52217 0.48366\\] average 0.56455\n",
    "\n",
    "hidden_layer_sizes=(3584, 1024, 1024, 1024, 256: f1-score \\[0.80774  0.84734 0.76555 0.75524\\] average 0.79397\n",
    "\n",
    "hidden_layer_sizes=(4096, 1024, 1024, 1024, 256): f1-score \\[0.79666 0.82218 0.83254 0.71084\\] average 0.79055"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "569a275d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de97331a",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08f8a439",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45293 entries, 0 to 45292\n",
      "Data columns (total 22 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   MM             45293 non-null  int64  \n",
      " 1   DD             45293 non-null  int64  \n",
      " 2   HH             45293 non-null  int64  \n",
      " 3   LOW_IMPACT     45293 non-null  bool   \n",
      " 4   MID_IMPACT     45293 non-null  bool   \n",
      " 5   BIG_IMPACT     45293 non-null  bool   \n",
      " 6   DIRECT_STRIKE  45293 non-null  bool   \n",
      " 7   00LAT          45293 non-null  float32\n",
      " 8   00LON          45293 non-null  float32\n",
      " 9   00WIND         45293 non-null  int32  \n",
      " 10  06LAT          45293 non-null  float32\n",
      " 11  06LON          45293 non-null  float32\n",
      " 12  06WIND         45293 non-null  int32  \n",
      " 13  12LAT          45293 non-null  float32\n",
      " 14  12LON          45293 non-null  float32\n",
      " 15  12WIND         45293 non-null  int32  \n",
      " 16  18LAT          45293 non-null  float32\n",
      " 17  18LON          45293 non-null  float32\n",
      " 18  18WIND         45293 non-null  int32  \n",
      " 19  24LAT          45293 non-null  float32\n",
      " 20  24LON          45293 non-null  float32\n",
      " 21  24WIND         45293 non-null  int32  \n",
      "dtypes: bool(4), float32(10), int32(5), int64(3)\n",
      "memory usage: 3.8 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# dataset = pd.read_pickle('../Dataset/baseline_dataset_tsnv_24.gz')\n",
    "dataset = pd.read_pickle('../Dataset/baseline_dataset.gz')\n",
    "pd.set_option(\"display.max.columns\", None)\n",
    "print(dataset.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "152cacb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, precision_recall_curve, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Constants\n",
    "TRAIN_RATIO = 0.9\n",
    "MAX_ITERS = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "192aab76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 36686; Dev set size: 4077; Testing set size: 4530\n"
     ]
    }
   ],
   "source": [
    "# test-dev-train split\n",
    "\n",
    "def separateDataset(dataset, train_ratio):\n",
    "    '''\n",
    "    Takes in a dataset (pandas df) and a ratio value, returns a dictionary containing the separated dataset.\n",
    "    Key \"train\" = train set, \"dev\" = dev set (size = train ratio * (sizeof input df - test set)), \"test\" = test set (size = train ratio * sizeof input df)\n",
    "    '''\n",
    "    train_dev_set, test_set = train_test_split(dataset, train_size=train_ratio, random_state=42)\n",
    "    train_set, dev_set = train_test_split(train_dev_set, train_size=train_ratio, random_state=42)\n",
    "    print(\"Training set size: {0}; Dev set size: {1}; Testing set size: {2}\".format(len(train_set), len(dev_set), len(test_set)))\n",
    "    return { \"train\": train_set, \"dev\": dev_set, \"test\": test_set }\n",
    "\n",
    "def pandasToXY(dataframe):\n",
    "    '''\n",
    "    converts the given pandas df to X and Y sub-arrays. X is pandas df, Y is np int array.\n",
    "    note: the range of columns to select as Y must be double checked when a different dataset is used.\n",
    "    '''\n",
    "    X = dataframe.drop(['LOW_IMPACT', 'MID_IMPACT', 'BIG_IMPACT', 'DIRECT_STRIKE'], axis=1)\n",
    "    # Y = np.asarray(dataframe.iloc[:,0:4]).astype(int)\n",
    "    Y = np.asarray(dataframe.iloc[:,3:7]).astype(int)\n",
    "    return X, Y\n",
    "\n",
    "# train-dev-test splitting\n",
    "splitDataset = separateDataset(dataset, TRAIN_RATIO)\n",
    "# separate each of the 3 sets into X and Y\n",
    "train_full = splitDataset[\"train\"]\n",
    "train_X, train_Y = pandasToXY(train_full)\n",
    "dev_full = splitDataset[\"dev\"]\n",
    "dev_X, dev_Y = pandasToXY(dev_full)\n",
    "test_full = splitDataset[\"test\"]\n",
    "test_X, test_Y = pandasToXY(test_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cb9290",
   "metadata": {},
   "source": [
    "### Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "117605f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from datetime import datetime\n",
    "\n",
    "def save_sklearn_model_to_file(model, model_type, filename=None):\n",
    "    '''Saves a sklearn model to file. Takes in the model, a name for the model and optionally a full filename.'''\n",
    "    if filename == None:\n",
    "        filename = \"./models/baseline_model_{0}_{1}.skl\".format(model_type, str(datetime.now().strftime(\"%Y-%m-%d %H-%M\")))\n",
    "        \n",
    "    joblib.dump(model, filename)\n",
    "    \n",
    "    # to load a model: model = joblib.load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ff517d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finds the best decision thresholds and the corresponding F1 scores\n",
    "# shows the precision-recall curve as well\n",
    "def optimize_thresholds(clf, datasetX, datasetY):\n",
    "    '''\n",
    "    Takes in a classifier, an input set X and a target set Y; returns the best decision thresholds and corresponding f1-scores;\n",
    "    displays the values and a precision recall curve.\n",
    "    '''\n",
    "    all_preds = clf.predict_proba(datasetX)\n",
    "    best_thresholds = []\n",
    "    best_f1_scores = []\n",
    "    n_classes = len(clf.classes_)\n",
    "    for i in range(n_classes):\n",
    "        precision, recall, thresholds = precision_recall_curve(datasetY[:,i], all_preds[:,i])\n",
    "        # find best threshold\n",
    "        fscore = (2 * precision * recall) / (precision + recall)\n",
    "        ix = np.nanargmax(fscore)\n",
    "        best_thresholds.append(thresholds[ix])\n",
    "        best_f1_scores.append(fscore[ix])\n",
    "        print('Best Threshold={0:.05f}, F-Score={1:.05f}'.format(thresholds[ix], fscore[ix]))\n",
    "    \n",
    "    # plot the precision-recall curve for the model\n",
    "    plt.plot(recall, precision, marker='.', label='PR curve')\n",
    "    plt.scatter(recall[ix], precision[ix], marker='o', color='black', label='Best')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve for Direct Strike')\n",
    "    plt.legend()\n",
    "        \n",
    "    return best_thresholds, best_f1_scores\n",
    "\n",
    "# make predictions according to the given thresholds\n",
    "def predictions_with_thresholds(clf, thresholds, datasetX):\n",
    "    '''\n",
    "    Takes in a classifier, a list of decision thresholds and an input samples set X;\n",
    "    Returns deterministic predictions made using the model over X and the thresholds.\n",
    "    '''\n",
    "    preds_probs = clf.predict_proba(datasetX)  \n",
    "    n_classes = len(clf.classes_)\n",
    "    preds = []\n",
    "    # iterate each predicted probability and compare against threshold\n",
    "    for i in range(len(preds_probs)):\n",
    "        pred_row = []\n",
    "        for j in range(n_classes):\n",
    "            if preds_probs[i,j] > thresholds[j]:\n",
    "                pred_row.append(1)\n",
    "            else:\n",
    "                pred_row.append(0)\n",
    "        preds.append(pred_row)\n",
    "    \n",
    "    return np.array(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8bc12204",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import expit\n",
    "\n",
    "def regression_predict(regr, datasetX, method='clip'):\n",
    "    '''\n",
    "    Takes in a regressor, an input samples set X and optionally a method argument (must be either \"sigmoid\" or \"clip\");\n",
    "    Returns predictions made by the regressor on X that have been rescaled to fall within [0,1] using the specified method.\n",
    "    '''\n",
    "    # method specifies how to handle inputs outside of 0-1 range: clip to 0 or 1, or pass through sigmoid\n",
    "    preds = regr.predict(datasetX)\n",
    "    if method == 'clip':\n",
    "        preds = np.clip(preds, 0, 1)\n",
    "    elif method == 'sigmoid':\n",
    "        preds = expit(preds)\n",
    "    return preds\n",
    "\n",
    "def regressor_find_thresholds(regr, datasetX, datasetY, method='clip'):\n",
    "    '''\n",
    "    Takes in a regressor, an input set X, a target set Y and optionally a scaling method;\n",
    "    returns the best decision thresholds and corresponding f1-scores;\n",
    "    displays the values and a precision recall curve.\n",
    "    '''\n",
    "    all_preds = regression_predict(regr, datasetX, method)\n",
    "    best_thresholds = []\n",
    "    best_f1_scores = []\n",
    "    for i in range(4):\n",
    "        precision, recall, thresholds = precision_recall_curve(datasetY[:,i], all_preds[:,i])\n",
    "        # find best threshold\n",
    "        fscore = (2 * precision * recall) / (precision + recall)\n",
    "        ix = np.nanargmax(fscore)\n",
    "        best_thresholds.append(thresholds[ix])\n",
    "        best_f1_scores.append(fscore[ix])\n",
    "        print('Best Threshold={0:.05f}, F-Score={1:.05f}'.format(thresholds[ix], fscore[ix]))\n",
    "\n",
    "    # plot the precision-recall curve for the model\n",
    "    plt.plot(recall, precision, marker='.', label='PR curve')\n",
    "    plt.scatter(recall[ix], precision[ix], marker='o', color='black', label='Best')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve for Direct Strike')\n",
    "    plt.legend()\n",
    "    \n",
    "    return best_thresholds, best_f1_scores\n",
    "\n",
    "def regression_label(regr, datasetX, thresholds, method='clip'):\n",
    "    '''\n",
    "    Takes in a regressor, a list of decision thresholds, an input samples set X and optionally a scaling method;\n",
    "    Returns deterministic predictions made using the model over X and the thresholds.\n",
    "    '''\n",
    "    preds_probs = regression_predict(regr, datasetX, method)\n",
    "    preds = []\n",
    "    # iterate each predicted probability and compare against threshold\n",
    "    for i in range(len(preds_probs)):\n",
    "        pred_row = []\n",
    "        for j in range(4):\n",
    "            if preds_probs[i,j] > thresholds[j]:\n",
    "                pred_row.append(1)\n",
    "            else:\n",
    "                pred_row.append(0)\n",
    "        preds.append(pred_row)\n",
    "    \n",
    "    return np.array(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef626a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4711e25",
   "metadata": {},
   "source": [
    "### Regressor\n",
    "\n",
    "(3072, 1024, 256): average f1 0.54347       \n",
    "(3072, 1024, 1024, 1024, 256): average f1 probably disastrous\n",
    "\n",
    "MLP regressors are likely unsuitable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "213c2f9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 14.75024329\n",
      "Iteration 2, loss = 0.08492585\n",
      "Iteration 3, loss = 0.05610611\n",
      "Iteration 4, loss = 0.05792739\n",
      "Iteration 5, loss = 0.05819284\n",
      "Iteration 6, loss = 0.05174721\n",
      "Iteration 7, loss = 0.05021901\n",
      "Iteration 8, loss = 0.05063860\n",
      "Iteration 9, loss = 0.05129845\n",
      "Iteration 10, loss = 0.04806291\n",
      "Iteration 11, loss = 0.04787761\n",
      "Iteration 12, loss = 0.04757031\n",
      "Iteration 13, loss = 0.04728702\n",
      "Iteration 14, loss = 0.04707625\n",
      "Iteration 15, loss = 0.04733981\n",
      "Iteration 16, loss = 0.04727447\n",
      "Iteration 17, loss = 0.04608255\n",
      "Iteration 18, loss = 0.04575512\n",
      "Iteration 19, loss = 0.04547080\n",
      "Iteration 20, loss = 0.04553568\n",
      "Iteration 21, loss = 0.04538387\n",
      "Iteration 22, loss = 0.04498728\n",
      "Iteration 23, loss = 0.04458605\n",
      "Iteration 24, loss = 0.04442632\n",
      "Iteration 25, loss = 0.04437355\n",
      "Iteration 26, loss = 0.04422562\n",
      "Iteration 27, loss = 0.04388001\n",
      "Iteration 28, loss = 0.04628849\n",
      "Iteration 29, loss = 0.04411449\n",
      "Iteration 30, loss = 0.04372437\n",
      "Iteration 31, loss = 0.04342731\n",
      "Iteration 32, loss = 0.04311229\n",
      "Iteration 33, loss = 0.04278538\n",
      "Iteration 34, loss = 0.04270644\n",
      "Iteration 35, loss = 0.04253311\n",
      "Iteration 36, loss = 0.04244961\n",
      "Iteration 37, loss = 0.04203795\n",
      "Iteration 38, loss = 0.04217490\n",
      "Iteration 39, loss = 0.04227698\n",
      "Iteration 40, loss = 0.04171863\n",
      "Iteration 41, loss = 0.04159014\n",
      "Iteration 42, loss = 0.04151159\n",
      "Iteration 43, loss = 0.04125116\n",
      "Iteration 44, loss = 0.04135436\n",
      "Iteration 45, loss = 0.04107201\n",
      "Iteration 46, loss = 0.04050799\n",
      "Iteration 47, loss = 0.04100483\n",
      "Iteration 48, loss = 0.04088458\n",
      "Iteration 49, loss = 0.04041105\n",
      "Iteration 50, loss = 0.04095226\n",
      "Iteration 51, loss = 0.04051138\n",
      "Iteration 52, loss = 0.04011532\n",
      "Iteration 53, loss = 0.04018218\n",
      "Iteration 54, loss = 0.03984996\n",
      "Iteration 55, loss = 0.03986989\n",
      "Iteration 56, loss = 0.03974214\n",
      "Iteration 57, loss = 0.03921016\n",
      "Iteration 58, loss = 0.04078463\n",
      "Iteration 59, loss = 0.03972851\n",
      "Iteration 60, loss = 0.03941589\n",
      "Iteration 61, loss = 0.03910924\n",
      "Iteration 62, loss = 0.03962802\n",
      "Iteration 63, loss = 0.03901555\n",
      "Iteration 64, loss = 0.03931727\n",
      "Iteration 65, loss = 0.03848478\n",
      "Iteration 66, loss = 0.03845537\n",
      "Iteration 67, loss = 0.03862084\n",
      "Iteration 68, loss = 0.03811360\n",
      "Iteration 69, loss = 0.03781804\n",
      "Iteration 70, loss = 0.03827133\n",
      "Iteration 71, loss = 0.03924210\n",
      "Iteration 72, loss = 0.03848147\n",
      "Iteration 73, loss = 0.03773122\n",
      "Iteration 74, loss = 0.03726910\n",
      "Iteration 75, loss = 0.03695330\n",
      "Iteration 76, loss = 0.03661884\n",
      "Iteration 77, loss = 0.03701984\n",
      "Iteration 78, loss = 0.03628901\n",
      "Iteration 79, loss = 0.03631291\n",
      "Iteration 80, loss = 0.03716480\n",
      "Iteration 81, loss = 0.03708740\n",
      "Iteration 82, loss = 0.03613982\n",
      "Iteration 83, loss = 0.03594169\n",
      "Iteration 84, loss = 0.03603704\n",
      "Iteration 85, loss = 0.03562542\n",
      "Iteration 86, loss = 0.03531611\n",
      "Iteration 87, loss = 0.03529163\n",
      "Iteration 88, loss = 0.03560984\n",
      "Iteration 89, loss = 0.03482549\n",
      "Iteration 90, loss = 0.03448946\n",
      "Iteration 91, loss = 0.03505239\n",
      "Iteration 92, loss = 0.03448299\n",
      "Iteration 93, loss = 0.03456559\n",
      "Iteration 94, loss = 0.03430944\n",
      "Iteration 95, loss = 0.03430088\n",
      "Iteration 96, loss = 0.03380558\n",
      "Iteration 97, loss = 0.03374753\n",
      "Iteration 98, loss = 0.03359893\n",
      "Iteration 99, loss = 0.03367930\n",
      "Iteration 100, loss = 0.03330136\n",
      "Iteration 101, loss = 0.03458644\n",
      "Iteration 102, loss = 0.03558950\n",
      "Iteration 103, loss = 0.03480201\n",
      "Iteration 104, loss = 0.03412814\n",
      "Iteration 105, loss = 0.03436014\n",
      "Iteration 106, loss = 0.03365531\n",
      "Iteration 107, loss = 0.03326707\n",
      "Iteration 108, loss = 0.03430136\n",
      "Iteration 109, loss = 0.03322439\n",
      "Iteration 110, loss = 0.03295475\n",
      "Iteration 111, loss = 0.03273435\n",
      "Iteration 112, loss = 0.03227636\n",
      "Iteration 113, loss = 0.03202577\n",
      "Iteration 114, loss = 0.03202342\n",
      "Iteration 115, loss = 0.03159855\n",
      "Iteration 116, loss = 0.03182572\n",
      "Iteration 117, loss = 0.03113675\n",
      "Iteration 118, loss = 0.03149827\n",
      "Iteration 119, loss = 0.03140372\n",
      "Iteration 120, loss = 0.03122941\n",
      "Iteration 121, loss = 0.03139406\n",
      "Iteration 122, loss = 0.03128166\n",
      "Iteration 123, loss = 0.03062879\n",
      "Iteration 124, loss = 0.03037499\n",
      "Iteration 125, loss = 0.03008329\n",
      "Iteration 126, loss = 0.03058940\n",
      "Iteration 127, loss = 0.02972119\n",
      "Iteration 128, loss = 0.02988950\n",
      "Iteration 129, loss = 0.03056205\n",
      "Iteration 130, loss = 0.03030057\n",
      "Iteration 131, loss = 0.03019303\n",
      "Iteration 132, loss = 0.03021118\n",
      "Iteration 133, loss = 0.02951090\n",
      "Iteration 134, loss = 0.02950537\n",
      "Iteration 135, loss = 0.02926233\n",
      "Iteration 136, loss = 0.02894546\n",
      "Iteration 137, loss = 0.02870521\n",
      "Iteration 138, loss = 0.02929639\n",
      "Iteration 139, loss = 0.03001396\n",
      "Iteration 140, loss = 0.02853530\n",
      "Iteration 141, loss = 0.02930640\n",
      "Iteration 142, loss = 0.02930348\n",
      "Iteration 143, loss = 0.02797135\n",
      "Iteration 144, loss = 0.02874258\n",
      "Iteration 145, loss = 0.02879296\n",
      "Iteration 146, loss = 0.02794126\n",
      "Iteration 147, loss = 0.02746498\n",
      "Iteration 148, loss = 0.02805919\n",
      "Iteration 149, loss = 0.02748335\n",
      "Iteration 150, loss = 0.02886713\n",
      "Iteration 151, loss = 0.02708813\n",
      "Iteration 152, loss = 0.02808417\n",
      "Iteration 153, loss = 0.02693335\n",
      "Iteration 154, loss = 0.02740854\n",
      "Iteration 155, loss = 0.02749393\n",
      "Iteration 156, loss = 0.02637879\n",
      "Iteration 157, loss = 0.02697176\n",
      "Iteration 158, loss = 0.02664279\n",
      "Iteration 159, loss = 0.02667361\n",
      "Iteration 160, loss = 0.02620039\n",
      "Iteration 161, loss = 0.02626976\n",
      "Iteration 162, loss = 0.02685418\n",
      "Iteration 163, loss = 0.02615622\n",
      "Iteration 164, loss = 0.02641168\n",
      "Iteration 165, loss = 0.02573044\n",
      "Iteration 166, loss = 0.02607654\n",
      "Iteration 167, loss = 0.02589481\n",
      "Iteration 168, loss = 0.02585986\n",
      "Iteration 169, loss = 0.02515355\n",
      "Iteration 170, loss = 0.02550916\n",
      "Iteration 171, loss = 0.02557644\n",
      "Iteration 172, loss = 0.02472325\n",
      "Iteration 173, loss = 0.02546558\n",
      "Iteration 174, loss = 0.02450759\n",
      "Iteration 175, loss = 0.02529700\n",
      "Iteration 176, loss = 0.02510246\n",
      "Iteration 177, loss = 0.02458172\n",
      "Iteration 178, loss = 0.02542644\n",
      "Iteration 179, loss = 0.02424318\n",
      "Iteration 180, loss = 0.02460307\n",
      "Iteration 181, loss = 0.02372549\n",
      "Iteration 182, loss = 0.02394110\n",
      "Iteration 183, loss = 0.02437524\n",
      "Iteration 184, loss = 0.02385636\n",
      "Iteration 185, loss = 0.02443233\n",
      "Iteration 186, loss = 0.02383405\n",
      "Iteration 187, loss = 0.02349508\n",
      "Iteration 188, loss = 0.02357902\n",
      "Iteration 189, loss = 0.02418068\n",
      "Iteration 190, loss = 0.02310773\n",
      "Iteration 191, loss = 0.02346904\n",
      "Iteration 192, loss = 0.02283130\n",
      "Iteration 193, loss = 0.02404224\n",
      "Iteration 194, loss = 0.02310123\n",
      "Iteration 195, loss = 0.02255632\n",
      "Iteration 196, loss = 0.02247588\n",
      "Iteration 197, loss = 0.02246880\n",
      "Iteration 198, loss = 0.02295504\n",
      "Iteration 199, loss = 0.02251666\n",
      "Iteration 200, loss = 0.02236285\n",
      "Iteration 201, loss = 0.02190862\n",
      "Iteration 202, loss = 0.02277096\n",
      "Iteration 203, loss = 0.02196091\n",
      "Iteration 204, loss = 0.02209331\n",
      "Iteration 205, loss = 0.02180874\n",
      "Iteration 206, loss = 0.02122736\n",
      "Iteration 207, loss = 0.02145287\n",
      "Iteration 208, loss = 0.02132915\n",
      "Iteration 209, loss = 0.02110967\n",
      "Iteration 210, loss = 0.02113487\n",
      "Iteration 211, loss = 0.02086961\n",
      "Iteration 212, loss = 0.02130106\n",
      "Iteration 213, loss = 0.02099622\n",
      "Iteration 214, loss = 0.02033279\n",
      "Iteration 215, loss = 0.02088224\n",
      "Iteration 216, loss = 0.02204949\n",
      "Iteration 217, loss = 0.02029633\n",
      "Iteration 218, loss = 0.02077230\n",
      "Iteration 219, loss = 0.02047383\n",
      "Iteration 220, loss = 0.02005022\n",
      "Iteration 221, loss = 0.02078745\n",
      "Iteration 222, loss = 0.02034589\n",
      "Iteration 223, loss = 0.01955417\n",
      "Iteration 224, loss = 0.02013046\n",
      "Iteration 225, loss = 0.02035872\n",
      "Iteration 226, loss = 0.01952255\n",
      "Iteration 227, loss = 0.01972086\n",
      "Iteration 228, loss = 0.01957566\n",
      "Iteration 229, loss = 0.01907319\n",
      "Iteration 230, loss = 0.01949595\n",
      "Iteration 231, loss = 0.01917703\n",
      "Iteration 232, loss = 0.01940815\n",
      "Iteration 233, loss = 0.01927651\n",
      "Iteration 234, loss = 0.01861912\n",
      "Iteration 235, loss = 0.01833624\n",
      "Iteration 236, loss = 0.01890166\n",
      "Iteration 237, loss = 0.01910744\n",
      "Iteration 238, loss = 0.01887031\n",
      "Iteration 239, loss = 0.01817489\n",
      "Iteration 240, loss = 0.01845164\n",
      "Iteration 241, loss = 0.01770768\n",
      "Iteration 242, loss = 0.01822498\n",
      "Iteration 243, loss = 0.01811974\n",
      "Iteration 244, loss = 0.01772262\n",
      "Iteration 245, loss = 0.01748393\n",
      "Iteration 246, loss = 0.01761396\n",
      "Iteration 247, loss = 0.01774742\n",
      "Iteration 248, loss = 0.01796129\n",
      "Iteration 249, loss = 0.01697734\n",
      "Iteration 250, loss = 0.01751348\n",
      "Iteration 251, loss = 0.01722566\n",
      "Iteration 252, loss = 0.01700342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 253, loss = 0.01702976\n",
      "Iteration 254, loss = 0.01726074\n",
      "Iteration 255, loss = 0.01687828\n",
      "Iteration 256, loss = 0.01690149\n",
      "Iteration 257, loss = 0.01659942\n",
      "Iteration 258, loss = 0.01594122\n",
      "Iteration 259, loss = 0.01628195\n",
      "Iteration 260, loss = 0.01652797\n",
      "Iteration 261, loss = 0.01703423\n",
      "Iteration 262, loss = 0.01673236\n",
      "Iteration 263, loss = 0.01569915\n",
      "Iteration 264, loss = 0.01620148\n",
      "Iteration 265, loss = 0.01662544\n",
      "Iteration 266, loss = 0.01587135\n",
      "Iteration 267, loss = 0.01616655\n",
      "Iteration 268, loss = 0.01535302\n",
      "Iteration 269, loss = 0.01611028\n",
      "Iteration 270, loss = 0.01529769\n",
      "Iteration 271, loss = 0.01603482\n",
      "Iteration 272, loss = 0.01514365\n",
      "Iteration 273, loss = 0.01531903\n",
      "Iteration 274, loss = 0.01554437\n",
      "Iteration 275, loss = 0.01585334\n",
      "Iteration 276, loss = 0.01627159\n",
      "Iteration 277, loss = 0.01497305\n",
      "Iteration 278, loss = 0.01450347\n",
      "Iteration 279, loss = 0.01565199\n",
      "Iteration 280, loss = 0.01512405\n",
      "Iteration 281, loss = 0.01614275\n",
      "Iteration 282, loss = 0.01438375\n",
      "Iteration 283, loss = 0.01430908\n",
      "Iteration 284, loss = 0.01515604\n",
      "Iteration 285, loss = 0.01542142\n",
      "Iteration 286, loss = 0.01435643\n",
      "Iteration 287, loss = 0.01453529\n",
      "Iteration 288, loss = 0.01408368\n",
      "Iteration 289, loss = 0.01471709\n",
      "Iteration 290, loss = 0.01377672\n",
      "Iteration 291, loss = 0.01430757\n",
      "Iteration 292, loss = 0.01442981\n",
      "Iteration 293, loss = 0.01402973\n",
      "Iteration 294, loss = 0.01443514\n",
      "Iteration 295, loss = 0.01391387\n",
      "Iteration 296, loss = 0.01352956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/userhome/cs/u3556490/anaconda3/envs/test/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:699: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    }
   ],
   "source": [
    "mlp_regr = MLPRegressor(\n",
    "    hidden_layer_sizes=(3072, 1024, 1024, 1024, 256),\n",
    "    batch_size=512,\n",
    "    alpha=0.01,\n",
    "    max_iter=MAX_ITERS,\n",
    "    shuffle=True,\n",
    "    verbose=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "mlp_regr = mlp_regr.fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f286b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold=0.47606, F-Score=0.69748\n",
      "Best Threshold=0.45027, F-Score=0.70125\n",
      "Best Threshold=0.40649, F-Score=0.59330\n",
      "Best Threshold=0.27487, F-Score=0.47514\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = regression_predict(mlp_regr, dev_X)\n",
    "best_thresholds, best_f1_scores = regressor_find_thresholds(mlp_regr, dev_X, dev_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ec802a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.73156   0.66310   0.69565       374\n",
      "           1    0.66781   0.73308   0.69892       266\n",
      "           2    0.52586   0.66304   0.58654        92\n",
      "           3    0.38532   0.59155   0.46667        71\n",
      "\n",
      "   micro avg    0.63785   0.67995   0.65823       803\n",
      "   macro avg    0.57764   0.66269   0.61195       803\n",
      "weighted avg    0.65626   0.67995   0.66399       803\n",
      " samples avg    0.06757   0.07350   0.06728       803\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = regression_label(mlp_regr, dev_X, best_thresholds)\n",
    "print(classification_report(dev_Y, preds, zero_division=0, digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04553f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4830675747574118\n",
      "0.383707748984343\n"
     ]
    }
   ],
   "source": [
    "print(mlp_regr.score(train_X, train_Y))\n",
    "print(mlp_regr.score(dev_X, dev_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6990f4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_sklearn_model_to_file(mlp_regr, \"mlpregr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6823dd5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.19299927\n",
      "Iteration 2, loss = 0.71405397\n",
      "Iteration 3, loss = 0.68443129\n",
      "Iteration 4, loss = 0.65849089\n",
      "Iteration 5, loss = 0.64869001\n",
      "Iteration 6, loss = 0.65767443\n",
      "Iteration 7, loss = 0.64435090\n",
      "Iteration 8, loss = 0.63556792\n",
      "Iteration 9, loss = 0.64348854\n",
      "Iteration 10, loss = 0.63039427\n",
      "Iteration 11, loss = 0.62911193\n",
      "Iteration 12, loss = 0.62900580\n",
      "Iteration 13, loss = 0.61720098\n",
      "Iteration 14, loss = 0.62790542\n",
      "Iteration 15, loss = 0.62271668\n",
      "Iteration 16, loss = 0.62045057\n",
      "Iteration 17, loss = 0.60945564\n",
      "Iteration 18, loss = 0.61035001\n",
      "Iteration 19, loss = 0.59769126\n",
      "Iteration 20, loss = 0.61402672\n",
      "Iteration 21, loss = 0.60349351\n",
      "Iteration 22, loss = 0.59042426\n",
      "Iteration 23, loss = 0.59558604\n",
      "Iteration 24, loss = 0.59173804\n",
      "Iteration 25, loss = 0.58976217\n",
      "Iteration 26, loss = 0.58463908\n",
      "Iteration 27, loss = 0.60627271\n",
      "Iteration 28, loss = 0.58100658\n",
      "Iteration 29, loss = 0.58558944\n",
      "Iteration 30, loss = 0.57848325\n",
      "Iteration 31, loss = 0.56545045\n",
      "Iteration 32, loss = 0.59039607\n",
      "Iteration 33, loss = 0.57111603\n",
      "Iteration 34, loss = 0.56113400\n",
      "Iteration 35, loss = 0.55941942\n",
      "Iteration 36, loss = 0.56800351\n",
      "Iteration 37, loss = 0.54674696\n",
      "Iteration 38, loss = 0.54166919\n",
      "Iteration 39, loss = 0.55710443\n",
      "Iteration 40, loss = 0.54937184\n",
      "Iteration 41, loss = 0.54000335\n",
      "Iteration 42, loss = 0.55720433\n",
      "Iteration 43, loss = 0.52325956\n",
      "Iteration 44, loss = 0.52402885\n",
      "Iteration 45, loss = 0.51574690\n",
      "Iteration 46, loss = 0.50512192\n",
      "Iteration 47, loss = 0.50969359\n",
      "Iteration 48, loss = 0.53001488\n",
      "Iteration 49, loss = 0.50014406\n",
      "Iteration 50, loss = 0.50865497\n",
      "Iteration 51, loss = 0.49397093\n",
      "Iteration 52, loss = 0.49152569\n",
      "Iteration 53, loss = 0.51044538\n",
      "Iteration 54, loss = 0.47722021\n",
      "Iteration 55, loss = 0.48523119\n",
      "Iteration 56, loss = 0.47214943\n",
      "Iteration 57, loss = 0.46702014\n",
      "Iteration 58, loss = 0.49126612\n",
      "Iteration 59, loss = 0.44507648\n",
      "Iteration 60, loss = 0.46275765\n",
      "Iteration 61, loss = 0.44842368\n",
      "Iteration 62, loss = 0.45268573\n",
      "Iteration 63, loss = 0.44861538\n",
      "Iteration 64, loss = 0.42741433\n",
      "Iteration 65, loss = 0.42421305\n",
      "Iteration 66, loss = 0.42889168\n",
      "Iteration 67, loss = 0.43690219\n",
      "Iteration 68, loss = 0.45327129\n",
      "Iteration 69, loss = 0.43921303\n",
      "Iteration 70, loss = 0.42818428\n",
      "Iteration 71, loss = 0.41486085\n",
      "Iteration 72, loss = 0.42670997\n",
      "Iteration 73, loss = 0.41985377\n",
      "Iteration 74, loss = 0.41202391\n",
      "Iteration 75, loss = 0.40813523\n",
      "Iteration 76, loss = 0.38978182\n",
      "Iteration 77, loss = 0.42369305\n",
      "Iteration 78, loss = 0.40419786\n",
      "Iteration 79, loss = 0.40835617\n",
      "Iteration 80, loss = 0.39191833\n",
      "Iteration 81, loss = 0.38493163\n",
      "Iteration 82, loss = 0.39181247\n",
      "Iteration 83, loss = 0.40017131\n",
      "Iteration 84, loss = 0.38267107\n",
      "Iteration 85, loss = 0.39051155\n",
      "Iteration 86, loss = 0.36395991\n",
      "Iteration 87, loss = 0.38296967\n",
      "Iteration 88, loss = 0.37905903\n",
      "Iteration 89, loss = 0.37141655\n",
      "Iteration 90, loss = 0.40393034\n",
      "Iteration 91, loss = 0.35677571\n",
      "Iteration 92, loss = 0.34806683\n",
      "Iteration 93, loss = 0.34843716\n",
      "Iteration 94, loss = 0.36258071\n",
      "Iteration 95, loss = 0.35461764\n",
      "Iteration 96, loss = 0.36211267\n",
      "Iteration 97, loss = 0.35724751\n",
      "Iteration 98, loss = 0.34688518\n",
      "Iteration 99, loss = 0.34448067\n",
      "Iteration 100, loss = 0.33853615\n",
      "Iteration 101, loss = 0.34274370\n",
      "Iteration 102, loss = 0.31576805\n",
      "Iteration 103, loss = 0.32874559\n",
      "Iteration 104, loss = 0.32067337\n",
      "Iteration 105, loss = 0.32289836\n",
      "Iteration 106, loss = 0.31028020\n",
      "Iteration 107, loss = 0.32334358\n",
      "Iteration 108, loss = 0.33182450\n",
      "Iteration 109, loss = 0.29533042\n",
      "Iteration 110, loss = 0.32259551\n",
      "Iteration 111, loss = 0.32425087\n",
      "Iteration 112, loss = 0.28146104\n",
      "Iteration 113, loss = 0.33495596\n",
      "Iteration 114, loss = 0.31685220\n",
      "Iteration 115, loss = 0.29499978\n",
      "Iteration 116, loss = 0.28472105\n",
      "Iteration 117, loss = 0.28642032\n",
      "Iteration 118, loss = 0.28357631\n",
      "Iteration 119, loss = 0.27054341\n",
      "Iteration 120, loss = 0.28387947\n",
      "Iteration 121, loss = 0.26055579\n",
      "Iteration 122, loss = 0.27737442\n",
      "Iteration 123, loss = 0.27909290\n",
      "Iteration 124, loss = 0.28265783\n",
      "Iteration 125, loss = 0.26130387\n",
      "Iteration 126, loss = 0.25762116\n",
      "Iteration 127, loss = 0.29525841\n",
      "Iteration 128, loss = 0.24124743\n",
      "Iteration 129, loss = 0.24749604\n",
      "Iteration 130, loss = 0.33818915\n",
      "Iteration 131, loss = 0.25361070\n",
      "Iteration 132, loss = 0.26787607\n",
      "Iteration 133, loss = 0.27041338\n",
      "Iteration 134, loss = 0.20824231\n",
      "Iteration 135, loss = 0.21109595\n",
      "Iteration 136, loss = 0.22230970\n",
      "Iteration 137, loss = 0.23384493\n",
      "Iteration 138, loss = 0.21861550\n",
      "Iteration 139, loss = 0.21408075\n",
      "Iteration 140, loss = 0.22656508\n",
      "Iteration 141, loss = 0.20450116\n",
      "Iteration 142, loss = 0.21338773\n",
      "Iteration 143, loss = 0.23364276\n",
      "Iteration 144, loss = 0.20790397\n",
      "Iteration 145, loss = 0.18146931\n",
      "Iteration 146, loss = 0.23371484\n",
      "Iteration 147, loss = 0.22723333\n",
      "Iteration 148, loss = 0.19055899\n",
      "Iteration 149, loss = 0.20916100\n",
      "Iteration 150, loss = 0.17432547\n",
      "Iteration 151, loss = 0.16838886\n",
      "Iteration 152, loss = 0.15954782\n",
      "Iteration 153, loss = 0.15598863\n",
      "Iteration 154, loss = 0.17103996\n",
      "Iteration 155, loss = 0.20107832\n",
      "Iteration 156, loss = 0.19096738\n",
      "Iteration 157, loss = 0.18238170\n",
      "Iteration 158, loss = 0.18610128\n",
      "Iteration 159, loss = 0.19398380\n",
      "Iteration 160, loss = 0.16502300\n",
      "Iteration 161, loss = 0.14548976\n",
      "Iteration 162, loss = 0.16433277\n",
      "Iteration 163, loss = 0.20812152\n",
      "Iteration 164, loss = 0.16675874\n",
      "Iteration 165, loss = 0.15201894\n",
      "Iteration 166, loss = 0.15631371\n",
      "Iteration 167, loss = 0.14231802\n",
      "Iteration 168, loss = 0.17086506\n",
      "Iteration 169, loss = 0.13708715\n",
      "Iteration 170, loss = 0.15633647\n",
      "Iteration 171, loss = 0.15471598\n",
      "Iteration 172, loss = 0.15070728\n",
      "Iteration 173, loss = 0.14085535\n",
      "Iteration 174, loss = 0.18861496\n",
      "Iteration 175, loss = 0.17426993\n",
      "Iteration 176, loss = 0.15619452\n",
      "Iteration 177, loss = 0.15564251\n",
      "Iteration 178, loss = 0.11712091\n",
      "Iteration 179, loss = 0.12033867\n",
      "Iteration 180, loss = 0.15970881\n",
      "Iteration 181, loss = 0.15795088\n",
      "Iteration 182, loss = 0.15045249\n",
      "Iteration 183, loss = 0.15548203\n",
      "Iteration 184, loss = 0.13005096\n",
      "Iteration 185, loss = 0.12262828\n",
      "Iteration 186, loss = 0.10265116\n",
      "Iteration 187, loss = 0.12527801\n",
      "Iteration 188, loss = 0.11327564\n",
      "Iteration 189, loss = 0.11520894\n",
      "Iteration 190, loss = 0.15492317\n",
      "Iteration 191, loss = 0.11682610\n",
      "Iteration 192, loss = 0.11367489\n",
      "Iteration 193, loss = 0.10951072\n",
      "Iteration 194, loss = 0.15857683\n",
      "Iteration 195, loss = 0.12989259\n",
      "Iteration 196, loss = 0.08603649\n",
      "Iteration 197, loss = 0.09816896\n",
      "Iteration 198, loss = 0.16585566\n",
      "Iteration 199, loss = 0.10874873\n",
      "Iteration 200, loss = 0.11430036\n",
      "Iteration 201, loss = 0.08242252\n",
      "Iteration 202, loss = 0.13983495\n",
      "Iteration 203, loss = 0.13983614\n",
      "Iteration 204, loss = 0.19574424\n",
      "Iteration 205, loss = 0.11435518\n",
      "Iteration 206, loss = 0.09388172\n",
      "Iteration 207, loss = 0.11338541\n",
      "Iteration 208, loss = 0.08614869\n",
      "Iteration 209, loss = 0.08547710\n",
      "Iteration 210, loss = 0.19032321\n",
      "Iteration 211, loss = 0.11955262\n",
      "Iteration 212, loss = 0.08270487\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    }
   ],
   "source": [
    "mlp_clf = MLPClassifier(\n",
    "    hidden_layer_sizes=(3072, 1024, 1024, 1024, 256),\n",
    "    batch_size=512,\n",
    "    alpha=0.01,\n",
    "    max_iter=MAX_ITERS,\n",
    "    shuffle=True,\n",
    "    verbose=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "mlp_clf = mlp_clf.fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "faecdd9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold=0.36290, F-Score=0.80965\n",
      "Best Threshold=0.24985, F-Score=0.81720\n",
      "Best Threshold=0.51735, F-Score=0.73143\n",
      "Best Threshold=0.18072, F-Score=0.69182\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_thresholds, best_f1_scores = optimize_thresholds(mlp_clf, dev_X, dev_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "145b700c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.81132   0.80481   0.80805       374\n",
      "           1    0.78007   0.85338   0.81508       266\n",
      "           2    0.76829   0.68478   0.72414        92\n",
      "           3    0.62069   0.76056   0.68354        71\n",
      "\n",
      "   micro avg    0.77617   0.80324   0.78947       803\n",
      "   macro avg    0.74509   0.77589   0.75770       803\n",
      "weighted avg    0.77918   0.80324   0.78976       803\n",
      " samples avg    0.08799   0.09006   0.08677       803\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = predictions_with_thresholds(mlp_clf, best_thresholds, dev_X)\n",
    "print(classification_report(dev_Y, preds, zero_division=0, digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6a05820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9890421414163441\n",
      "0.9374540103016924\n"
     ]
    }
   ],
   "source": [
    "print(mlp_clf.score(train_X, train_Y))\n",
    "print(mlp_clf.score(dev_X, dev_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33164732",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_sklearn_model_to_file(mlp_clf, \"mlpclf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
