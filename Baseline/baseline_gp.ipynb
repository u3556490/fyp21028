{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51f13eaa",
   "metadata": {},
   "source": [
    "# Gaussian Processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b84d63fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING']=\"1\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import gpytorch\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "478d3bb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 2080 Ti\n",
      "8\n",
      "Sat Apr 16 14:27:19 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.103.01   Driver Version: 470.103.01   CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:05:00.0 Off |                  N/A |\n",
      "| 48%   76C    P2   155W / 250W |   3887MiB / 11019MiB |     14%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      8905      C   ...nda3/envs/test/bin/python      221MiB |\n",
      "|    0   N/A  N/A      8906      C   ...nda3/envs/test/bin/python      233MiB |\n",
      "|    0   N/A  N/A      8907      C   ...nda3/envs/test/bin/python      225MiB |\n",
      "|    0   N/A  N/A      8908      C   ...nda3/envs/test/bin/python      233MiB |\n",
      "|    0   N/A  N/A      8909      C   ...nda3/envs/test/bin/python      743MiB |\n",
      "|    0   N/A  N/A      8910      C   ...nda3/envs/test/bin/python      743MiB |\n",
      "|    0   N/A  N/A      8911      C   ...nda3/envs/test/bin/python      743MiB |\n",
      "|    0   N/A  N/A      8912      C   ...nda3/envs/test/bin/python      743MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.get_device_name() if torch.cuda.is_available() else \"No GPU\")\n",
    "print(os.cpu_count())\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d7f9ccb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45293 entries, 0 to 45292\n",
      "Data columns (total 22 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   MM             45293 non-null  int64  \n",
      " 1   DD             45293 non-null  int64  \n",
      " 2   HH             45293 non-null  int64  \n",
      " 3   LOW_IMPACT     45293 non-null  bool   \n",
      " 4   MID_IMPACT     45293 non-null  bool   \n",
      " 5   BIG_IMPACT     45293 non-null  bool   \n",
      " 6   DIRECT_STRIKE  45293 non-null  bool   \n",
      " 7   00LAT          45293 non-null  float32\n",
      " 8   00LON          45293 non-null  float32\n",
      " 9   00WIND         45293 non-null  int32  \n",
      " 10  06LAT          45293 non-null  float32\n",
      " 11  06LON          45293 non-null  float32\n",
      " 12  06WIND         45293 non-null  int32  \n",
      " 13  12LAT          45293 non-null  float32\n",
      " 14  12LON          45293 non-null  float32\n",
      " 15  12WIND         45293 non-null  int32  \n",
      " 16  18LAT          45293 non-null  float32\n",
      " 17  18LON          45293 non-null  float32\n",
      " 18  18WIND         45293 non-null  int32  \n",
      " 19  24LAT          45293 non-null  float32\n",
      " 20  24LON          45293 non-null  float32\n",
      " 21  24WIND         45293 non-null  int32  \n",
      "dtypes: bool(4), float32(10), int32(5), int64(3)\n",
      "memory usage: 3.8 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_pickle('../Dataset/baseline_dataset.gz')\n",
    "pd.set_option(\"display.max.columns\", None)\n",
    "print(dataset.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "835fcb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "TRAIN_RATIO = 0.9\n",
    "NUM_EPOCHS = 100\n",
    "LR = 0.1\n",
    "BATCH_SIZE = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c31e7d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 36686; Dev set size: 4077; Testing set size: 4530\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, precision_recall_curve, classification_report, brier_score_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# test-dev-train split\n",
    "def separateDataset(dataset, train_ratio):\n",
    "    '''\n",
    "    Takes in a dataset (pandas df) and a ratio value, returns a dictionary containing the separated dataset.\n",
    "    Key \"train\" = train set, \"dev\" = dev set (size = train ratio * (sizeof input df - test set)), \"test\" = test set (size = train ratio * sizeof input df)\n",
    "    '''\n",
    "    train_dev_set, test_set = train_test_split(dataset, train_size=train_ratio)\n",
    "    train_set, dev_set = train_test_split(train_dev_set, train_size=train_ratio)\n",
    "    print(\"Training set size: {0}; Dev set size: {1}; Testing set size: {2}\".format(len(train_set), len(dev_set), len(test_set)))\n",
    "    return { \"train\": train_set, \"dev\": dev_set, \"test\": test_set }\n",
    "\n",
    "def pandasToXY(dataframe):\n",
    "    '''\n",
    "    converts the given pandas df to X and Y sub-arrays. X is pandas df, Y is np int array.\n",
    "    note: the range of columns to select as Y must be double checked when a different dataset is used.\n",
    "    '''\n",
    "    X = dataframe.drop(['LOW_IMPACT', 'MID_IMPACT', 'BIG_IMPACT', 'DIRECT_STRIKE'], axis=1)\n",
    "    Y = np.asarray(dataframe.iloc[:,3:7]).astype(int)\n",
    "    return X, Y\n",
    "\n",
    "# split\n",
    "splitDataset = separateDataset(dataset, TRAIN_RATIO)\n",
    "# to XY\n",
    "train_X, train_Y = pandasToXY(splitDataset[\"train\"])\n",
    "dev_X, dev_Y = pandasToXY(splitDataset[\"dev\"])\n",
    "# to tensor\n",
    "train_X = torch.tensor(StandardScaler().fit_transform(train_X)).float()\n",
    "train_Y = torch.tensor(train_Y[:,0]).float()\n",
    "dev_X = torch.tensor(StandardScaler().fit_transform(dev_X)).float()\n",
    "dev_Y = torch.tensor(dev_Y[:,0]).float()\n",
    "# to dataloader\n",
    "train_loader = DataLoader(TensorDataset(train_X, train_Y), batch_size=BATCH_SIZE, shuffle=True)\n",
    "dev_loader = DataLoader(TensorDataset(dev_X, dev_Y), batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e00deeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import expit\n",
    "\n",
    "def regression_predict(preds, method='clip'):\n",
    "    '''\n",
    "    Takes in an array of raw predictions and optionally a method argument (must be either \"sigmoid\" or \"clip\");\n",
    "    Returns predictions made by the model that have been rescaled to fall within [0,1] using the specified method.\n",
    "    Note that the GP model is treated as if it were a regressor.\n",
    "    '''\n",
    "    # method specifies how to handle inputs outside of 0-1 range: clip to 0 or 1, or pass through sigmoid\n",
    "    if method == 'clip':\n",
    "        preds = np.clip(preds, 0, 1)\n",
    "    elif method == 'sigmoid':\n",
    "        preds = expit(preds)\n",
    "    return preds\n",
    "\n",
    "def regressor_find_thresholds(all_preds, datasetY, method='clip'):\n",
    "    '''\n",
    "    Takes in an array of predictions, a target set Y and optionally a scaling method;\n",
    "    returns the best decision thresholds and corresponding f1-scores;\n",
    "    displays the values and a precision recall curve.\n",
    "    '''\n",
    "    best_thresholds = []\n",
    "    best_f1_scores = []\n",
    "    for i in range(4):\n",
    "        precision, recall, thresholds = precision_recall_curve(datasetY[:,i], all_preds[:,i])\n",
    "        fscore = (2 * precision * recall) / (precision + recall)\n",
    "        ix = np.nanargmax(fscore)\n",
    "        best_thresholds.append(thresholds[ix])\n",
    "        best_f1_scores.append(fscore[ix])\n",
    "        print('Best Threshold={0:.05f}, F-Score={1:.05f}'.format(thresholds[ix], fscore[ix]))\n",
    "\n",
    "    # plot the precision-recall curve for the model\n",
    "    plt.plot(recall, precision, marker='.', label='PR curve')\n",
    "    plt.scatter(recall[ix], precision[ix], marker='o', color='black', label='Best')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve')\n",
    "    plt.legend()\n",
    "    \n",
    "    return best_thresholds, best_f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7186afea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from gpytorch.variational import CholeskyVariationalDistribution\n",
    "from gpytorch.variational import VariationalStrategy, IndependentMultitaskVariationalStrategy, LMCVariationalStrategy\n",
    "\n",
    "class ApproximateGPModel(gpytorch.models.ApproximateGP):\n",
    "    '''An approximate Gaussian process model is defined here'''\n",
    "    def __init__(self, inducing_points):        \n",
    "        variational_distribution = CholeskyVariationalDistribution(\n",
    "            inducing_points.size(0)#, batch_shape=torch.Size([2])\n",
    "        )\n",
    "        variational_strategy = VariationalStrategy(\n",
    "                self, inducing_points, variational_distribution, learn_inducing_locations=True\n",
    "        )\n",
    "        \n",
    "        '''LMCVariationalStrategy(\n",
    "            VariationalStrategy(\n",
    "                self, inducing_points, variational_distribution, learn_inducing_locations=True\n",
    "            ),\n",
    "            num_tasks=4, num_latents=2, latent_dim=-1\n",
    "        )'''\n",
    "        \n",
    "        super(ApproximateGPModel, self).__init__(variational_strategy)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(\n",
    "            gpytorch.kernels.RBFKernel()\n",
    "            #batch_shape=torch.Size([2])\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "    \n",
    "likelihood = gpytorch.likelihoods.BernoulliLikelihood()\n",
    "model = ApproximateGPModel(inducing_points=train_X[:5000,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "379f998b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()\n",
    "likelihood = likelihood.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bdc6e73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1/100 - Loss: 0.350   lengthscale: 1.942\n",
      "Iter 2/100 - Loss: 0.244   lengthscale: 2.136\n",
      "Iter 3/100 - Loss: 0.240   lengthscale: 2.042\n",
      "Iter 4/100 - Loss: 0.239   lengthscale: 1.973\n",
      "Iter 5/100 - Loss: 0.226   lengthscale: 1.827\n",
      "Iter 6/100 - Loss: 0.218   lengthscale: 1.676\n",
      "Iter 7/100 - Loss: 0.213   lengthscale: 1.677\n",
      "Iter 8/100 - Loss: 0.210   lengthscale: 1.675\n",
      "Iter 9/100 - Loss: 0.207   lengthscale: 1.666\n",
      "Iter 10/100 - Loss: 0.205   lengthscale: 1.601\n",
      "Iter 11/100 - Loss: 0.199   lengthscale: 1.646\n",
      "Iter 12/100 - Loss: 0.199   lengthscale: 1.688\n",
      "Iter 13/100 - Loss: 0.198   lengthscale: 1.733\n",
      "Iter 14/100 - Loss: 0.194   lengthscale: 1.704\n",
      "Iter 15/100 - Loss: 0.197   lengthscale: 1.572\n",
      "Iter 16/100 - Loss: 0.198   lengthscale: 1.726\n",
      "Iter 17/100 - Loss: 0.193   lengthscale: 1.693\n",
      "Iter 18/100 - Loss: 0.193   lengthscale: 1.727\n",
      "Iter 19/100 - Loss: 0.192   lengthscale: 1.675\n",
      "Iter 20/100 - Loss: 0.189   lengthscale: 1.696\n",
      "Iter 21/100 - Loss: 0.190   lengthscale: 1.794\n",
      "Iter 22/100 - Loss: 0.188   lengthscale: 1.789\n",
      "Iter 23/100 - Loss: 0.194   lengthscale: 1.724\n",
      "Iter 24/100 - Loss: 0.189   lengthscale: 1.685\n",
      "Iter 25/100 - Loss: 0.190   lengthscale: 1.755\n",
      "Iter 26/100 - Loss: 0.191   lengthscale: 1.730\n",
      "Iter 27/100 - Loss: 0.190   lengthscale: 1.827\n",
      "Iter 28/100 - Loss: 0.187   lengthscale: 1.764\n",
      "Iter 29/100 - Loss: 0.186   lengthscale: 1.868\n",
      "Iter 30/100 - Loss: 0.186   lengthscale: 1.807\n",
      "Iter 31/100 - Loss: 0.187   lengthscale: 1.720\n",
      "Iter 32/100 - Loss: 0.187   lengthscale: 1.714\n",
      "Iter 33/100 - Loss: 0.187   lengthscale: 1.822\n",
      "Iter 34/100 - Loss: 0.187   lengthscale: 1.846\n",
      "Iter 35/100 - Loss: 0.186   lengthscale: 1.904\n",
      "Iter 36/100 - Loss: 0.188   lengthscale: 1.808\n",
      "Iter 37/100 - Loss: 0.187   lengthscale: 1.860\n",
      "Iter 38/100 - Loss: 0.186   lengthscale: 1.938\n",
      "Iter 39/100 - Loss: 0.187   lengthscale: 1.899\n",
      "Iter 40/100 - Loss: 0.186   lengthscale: 1.805\n",
      "Iter 41/100 - Loss: 0.189   lengthscale: 1.798\n",
      "Iter 42/100 - Loss: 0.184   lengthscale: 1.821\n",
      "Iter 43/100 - Loss: 0.185   lengthscale: 1.911\n",
      "Iter 44/100 - Loss: 0.187   lengthscale: 1.919\n",
      "Iter 45/100 - Loss: 0.189   lengthscale: 1.792\n",
      "Iter 46/100 - Loss: 0.188   lengthscale: 1.774\n",
      "Iter 47/100 - Loss: 0.183   lengthscale: 1.911\n",
      "Iter 48/100 - Loss: 0.186   lengthscale: 1.957\n",
      "Iter 49/100 - Loss: 0.185   lengthscale: 1.824\n",
      "Iter 50/100 - Loss: 0.187   lengthscale: 1.841\n",
      "Iter 51/100 - Loss: 0.186   lengthscale: 1.873\n",
      "Iter 52/100 - Loss: 0.186   lengthscale: 1.927\n",
      "Iter 53/100 - Loss: 0.186   lengthscale: 1.811\n",
      "Iter 54/100 - Loss: 0.184   lengthscale: 1.797\n",
      "Iter 55/100 - Loss: 0.186   lengthscale: 1.875\n",
      "Iter 56/100 - Loss: 0.184   lengthscale: 1.837\n",
      "Iter 57/100 - Loss: 0.185   lengthscale: 1.884\n",
      "Iter 58/100 - Loss: 0.184   lengthscale: 1.917\n",
      "Iter 59/100 - Loss: 0.184   lengthscale: 1.928\n",
      "Iter 60/100 - Loss: 0.189   lengthscale: 1.733\n",
      "Iter 61/100 - Loss: 0.187   lengthscale: 1.881\n",
      "Iter 62/100 - Loss: 0.186   lengthscale: 1.905\n",
      "Iter 63/100 - Loss: 0.185   lengthscale: 1.928\n",
      "Iter 64/100 - Loss: 0.184   lengthscale: 1.892\n",
      "Iter 65/100 - Loss: 0.186   lengthscale: 1.749\n",
      "Iter 66/100 - Loss: 0.184   lengthscale: 1.900\n",
      "Iter 67/100 - Loss: 0.184   lengthscale: 1.886\n",
      "Iter 68/100 - Loss: 0.185   lengthscale: 1.809\n",
      "Iter 69/100 - Loss: 0.185   lengthscale: 1.858\n",
      "Iter 70/100 - Loss: 0.185   lengthscale: 1.841\n",
      "Iter 71/100 - Loss: 0.185   lengthscale: 1.851\n",
      "Iter 72/100 - Loss: 0.187   lengthscale: 1.788\n",
      "Iter 73/100 - Loss: 0.184   lengthscale: 1.900\n",
      "Iter 74/100 - Loss: 0.186   lengthscale: 1.865\n",
      "Iter 75/100 - Loss: 0.185   lengthscale: 1.941\n",
      "Iter 76/100 - Loss: 0.184   lengthscale: 1.881\n",
      "Iter 77/100 - Loss: 0.185   lengthscale: 1.885\n",
      "Iter 78/100 - Loss: 0.185   lengthscale: 1.964\n",
      "Iter 79/100 - Loss: 0.184   lengthscale: 1.885\n",
      "Iter 80/100 - Loss: 0.185   lengthscale: 1.874\n",
      "Iter 81/100 - Loss: 0.182   lengthscale: 1.887\n",
      "Iter 82/100 - Loss: 0.185   lengthscale: 1.882\n",
      "Iter 83/100 - Loss: 0.183   lengthscale: 1.947\n",
      "Iter 84/100 - Loss: 0.184   lengthscale: 1.805\n",
      "Iter 85/100 - Loss: 0.184   lengthscale: 1.968\n",
      "Iter 86/100 - Loss: 0.184   lengthscale: 1.956\n",
      "Iter 87/100 - Loss: 0.186   lengthscale: 1.959\n",
      "Iter 88/100 - Loss: 0.187   lengthscale: 1.703\n",
      "Iter 89/100 - Loss: 0.187   lengthscale: 1.825\n",
      "Iter 90/100 - Loss: 0.186   lengthscale: 1.935\n",
      "Iter 91/100 - Loss: 0.188   lengthscale: 1.898\n",
      "Iter 92/100 - Loss: 0.185   lengthscale: 1.934\n",
      "Iter 93/100 - Loss: 0.184   lengthscale: 1.875\n",
      "Iter 94/100 - Loss: 0.184   lengthscale: 1.967\n",
      "Iter 95/100 - Loss: 0.185   lengthscale: 1.930\n",
      "Iter 96/100 - Loss: 0.184   lengthscale: 1.899\n",
      "Iter 97/100 - Loss: 0.185   lengthscale: 1.845\n",
      "Iter 98/100 - Loss: 0.184   lengthscale: 1.817\n",
      "Iter 99/100 - Loss: 0.184   lengthscale: 1.825\n",
      "Iter 100/100 - Loss: 0.184   lengthscale: 1.882\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "optimizer = torch.optim.Adam([\n",
    "    {'params': model.parameters()}, \n",
    "    {'params': likelihood.parameters()}\n",
    "], lr=LR)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "# mll = gpytorch.mlls.VariationalELBO(likelihood, model, num_data=train_Y.size(0))\n",
    "mll = gpytorch.mlls.PredictiveLogLikelihood(likelihood, model, num_data=train_Y.size(0))\n",
    "\n",
    "for i in range(NUM_EPOCHS):\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for j, (inputs, targets) in enumerate(train_loader):\n",
    "        inputs = inputs.cuda()\n",
    "        targets = targets.cuda()        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(inputs)\n",
    "        loss = -mll(output, targets)\n",
    "        loss.backward()        \n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    average_loss = running_loss/len(train_loader)\n",
    "        \n",
    "    print('Iter %d/%d - Loss: %.3f   lengthscale: %.3f' % ( #   noise: %.3f\n",
    "        i + 1, NUM_EPOCHS, average_loss,\n",
    "        model.covar_module.base_kernel.lengthscale.item()\n",
    "        #model.covar_module.noise.item()\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9c7d40f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0151, 0.0247, 0.3820,  ..., 0.3566, 0.0266, 0.2896])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "all_preds = torch.tensor([])\n",
    "\n",
    "with torch.no_grad():\n",
    "    for j, (inputs, targets) in enumerate(dev_loader):\n",
    "        inputs = inputs.cuda()\n",
    "        preds = likelihood(model(inputs))\n",
    "        all_preds = torch.cat([all_preds, preds.probs.cpu()])\n",
    "    \n",
    "print(all_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02838e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold=0.00012, F-Score=0.16499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/.u3556490/ipykernel_9610/3743630220.py:4: RuntimeWarning: invalid value encountered in true_divide\n",
      "  fscore = (2 * precision * recall) / (precision + recall)\n"
     ]
    }
   ],
   "source": [
    "all_preds = np.clip(all_preds, 0, 1)\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(dev_Y, all_preds)\n",
    "fscore = (2 * precision * recall) / (precision + recall)\n",
    "ix = np.nanargmax(fscore)\n",
    "print('Best Threshold={0:.05f}, F-Score={1:.05f}'.format(thresholds[ix], fscore[ix]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7b954b13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold=0.51872, F-Score=0.16474\n",
      "Best Threshold=0.50932, F-Score=0.13912\n",
      "Best Threshold=0.49978, F-Score=0.05287\n",
      "Best Threshold=0.50370, F-Score=0.04706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20535/4130612801.py:16: RuntimeWarning: invalid value encountered in true_divide\n",
      "  fscore = (2 * precision * recall) / (precision + recall)\n",
      "/tmp/ipykernel_20535/4130612801.py:16: RuntimeWarning: invalid value encountered in true_divide\n",
      "  fscore = (2 * precision * recall) / (precision + recall)\n",
      "/tmp/ipykernel_20535/4130612801.py:16: RuntimeWarning: invalid value encountered in true_divide\n",
      "  fscore = (2 * precision * recall) / (precision + recall)\n",
      "/tmp/ipykernel_20535/4130612801.py:16: RuntimeWarning: invalid value encountered in true_divide\n",
      "  fscore = (2 * precision * recall) / (precision + recall)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.5187237, 0.5093235, 0.49978086, 0.5037002],\n",
       " [0.16473791695030635,\n",
       "  0.13911742707554228,\n",
       "  0.05286574195236849,\n",
       "  0.047058823529411764])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = regression_predict(means.numpy(), method='sigmoid')\n",
    "regressor_find_thresholds(preds, dev_Y, method='sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c337d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cpu()\n",
    "likelihood = likelihood.cpu()\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
