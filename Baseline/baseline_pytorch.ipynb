{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \\[Old\\] Baseline Model - MLP, PyTorch version\n",
    "\n",
    "Doesn't work, if at all. Dependencies:\n",
    "```\n",
    "- numpy\n",
    "- pandas\n",
    "- torch (with CUDA support and torchvision)\n",
    "- torchmetrics\n",
    "- matplotlib\n",
    "- seaborn\n",
    "- sklearn\n",
    "```\n",
    "\n",
    "### Importing libraries and reading files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING']=\"1\" # CUDA debug help\n",
    "# Import statements\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import sys\n",
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ GPU availability, CPU count and GPU status check ===============\n",
      "GeForce RTX 2080 Ti\n",
      "4\n",
      "Thu Jan  6 19:24:41 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.91.03    Driver Version: 460.91.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 208...  On   | 00000000:05:00.0 Off |                  N/A |\n",
      "| 18%   30C    P8     5W / 250W |      3MiB / 11019MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Check GPU and CPU count\n",
    "print(\"================ GPU availability, CPU count and GPU status check ===============\")\n",
    "print(torch.cuda.get_device_name() if torch.cuda.is_available() else \"No GPU\")\n",
    "print(os.cpu_count())\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/userhome/cs/u3556490/efyp/Baseline\r\n"
     ]
    }
   ],
   "source": [
    "# Set path (optional)\n",
    "'''dataset_dir = '../Dataset'\n",
    "sys.path.append(dataset_dir)'''\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ Reading dataset, null check ===============\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45293 entries, 0 to 45292\n",
      "Data columns (total 22 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   MM             45293 non-null  int64  \n",
      " 1   DD             45293 non-null  int64  \n",
      " 2   HH             45293 non-null  int64  \n",
      " 3   LOW_IMPACT     45293 non-null  bool   \n",
      " 4   MID_IMPACT     45293 non-null  bool   \n",
      " 5   BIG_IMPACT     45293 non-null  bool   \n",
      " 6   DIRECT_STRIKE  45293 non-null  bool   \n",
      " 7   00LAT          45293 non-null  float32\n",
      " 8   00LON          45293 non-null  float32\n",
      " 9   00WIND         45293 non-null  int32  \n",
      " 10  06LAT          45293 non-null  float32\n",
      " 11  06LON          45293 non-null  float32\n",
      " 12  06WIND         45293 non-null  int32  \n",
      " 13  12LAT          45293 non-null  float32\n",
      " 14  12LON          45293 non-null  float32\n",
      " 15  12WIND         45293 non-null  int32  \n",
      " 16  18LAT          45293 non-null  float32\n",
      " 17  18LON          45293 non-null  float32\n",
      " 18  18WIND         45293 non-null  int32  \n",
      " 19  24LAT          45293 non-null  float32\n",
      " 20  24LON          45293 non-null  float32\n",
      " 21  24WIND         45293 non-null  int32  \n",
      "dtypes: bool(4), float32(10), int32(5), int64(3)\n",
      "memory usage: 3.8 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# read Dataset as Pandas DataFrame\n",
    "print(\"================ Reading dataset, null check ===============\")\n",
    "dataset = pd.read_pickle('../Dataset/baseline_dataset.gz')\n",
    "pd.set_option(\"display.max.columns\", None)\n",
    "print(dataset.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null checking:\n",
      "Empty DataFrame\n",
      "Columns: [MM, DD, HH, LOW_IMPACT, MID_IMPACT, BIG_IMPACT, DIRECT_STRIKE, 00LAT, 00LON, 00WIND, 06LAT, 06LON, 06WIND, 12LAT, 12LON, 12WIND, 18LAT, 18LON, 18WIND, 24LAT, 24LON, 24WIND]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# san-check: any nulls?\n",
    "print(\"Null checking:\")\n",
    "print(dataset[dataset.isnull().any(axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MM</th>\n",
       "      <th>DD</th>\n",
       "      <th>HH</th>\n",
       "      <th>00LAT</th>\n",
       "      <th>00LON</th>\n",
       "      <th>00WIND</th>\n",
       "      <th>06LAT</th>\n",
       "      <th>06LON</th>\n",
       "      <th>06WIND</th>\n",
       "      <th>12LAT</th>\n",
       "      <th>12LON</th>\n",
       "      <th>12WIND</th>\n",
       "      <th>18LAT</th>\n",
       "      <th>18LON</th>\n",
       "      <th>18WIND</th>\n",
       "      <th>24LAT</th>\n",
       "      <th>24LON</th>\n",
       "      <th>24WIND</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>45293.000000</td>\n",
       "      <td>45293.000000</td>\n",
       "      <td>45293.000000</td>\n",
       "      <td>45293.000000</td>\n",
       "      <td>45293.000000</td>\n",
       "      <td>45293.000000</td>\n",
       "      <td>45293.000000</td>\n",
       "      <td>45293.000000</td>\n",
       "      <td>45293.000000</td>\n",
       "      <td>45293.000000</td>\n",
       "      <td>45293.000000</td>\n",
       "      <td>45293.000000</td>\n",
       "      <td>45293.000000</td>\n",
       "      <td>45293.000000</td>\n",
       "      <td>45293.000000</td>\n",
       "      <td>45293.000000</td>\n",
       "      <td>45293.000000</td>\n",
       "      <td>45293.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.283068</td>\n",
       "      <td>16.061025</td>\n",
       "      <td>8.918111</td>\n",
       "      <td>20.017653</td>\n",
       "      <td>132.009323</td>\n",
       "      <td>62.021063</td>\n",
       "      <td>19.506798</td>\n",
       "      <td>132.481476</td>\n",
       "      <td>62.087077</td>\n",
       "      <td>19.018631</td>\n",
       "      <td>132.967087</td>\n",
       "      <td>61.773122</td>\n",
       "      <td>18.551769</td>\n",
       "      <td>133.451675</td>\n",
       "      <td>61.072020</td>\n",
       "      <td>18.104473</td>\n",
       "      <td>133.910690</td>\n",
       "      <td>60.020864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.310187</td>\n",
       "      <td>8.633509</td>\n",
       "      <td>6.698948</td>\n",
       "      <td>7.507561</td>\n",
       "      <td>19.457451</td>\n",
       "      <td>31.469743</td>\n",
       "      <td>7.243189</td>\n",
       "      <td>18.568924</td>\n",
       "      <td>31.423058</td>\n",
       "      <td>7.016464</td>\n",
       "      <td>17.948254</td>\n",
       "      <td>31.615497</td>\n",
       "      <td>6.824604</td>\n",
       "      <td>17.685791</td>\n",
       "      <td>31.978523</td>\n",
       "      <td>6.662520</td>\n",
       "      <td>17.910883</td>\n",
       "      <td>32.433757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>-179.899994</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>-179.899994</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>-179.899994</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>-179.899994</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>-180.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.500000</td>\n",
       "      <td>121.800003</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>14.200000</td>\n",
       "      <td>122.400002</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>13.900000</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>13.600000</td>\n",
       "      <td>123.500000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>13.200000</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>19.200001</td>\n",
       "      <td>131.300003</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>18.799999</td>\n",
       "      <td>131.600006</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>18.400000</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>132.399994</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>17.600000</td>\n",
       "      <td>132.800003</td>\n",
       "      <td>55.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>24.700001</td>\n",
       "      <td>142.399994</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>24.100000</td>\n",
       "      <td>142.699997</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>23.500000</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>22.900000</td>\n",
       "      <td>143.399994</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>22.299999</td>\n",
       "      <td>143.899994</td>\n",
       "      <td>80.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>55.500000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>54.500000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>53.500000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>50.500000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>185.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 MM            DD            HH         00LAT         00LON  \\\n",
       "count  45293.000000  45293.000000  45293.000000  45293.000000  45293.000000   \n",
       "mean       8.283068     16.061025      8.918111     20.017653    132.009323   \n",
       "std        2.310187      8.633509      6.698948      7.507561     19.457451   \n",
       "min        1.000000      1.000000      0.000000      1.300000   -179.899994   \n",
       "25%        7.000000      9.000000      0.000000     14.500000    121.800003   \n",
       "50%        8.000000     16.000000      6.000000     19.200001    131.300003   \n",
       "75%       10.000000     23.000000     12.000000     24.700001    142.399994   \n",
       "max       12.000000     31.000000     23.000000     55.500000    180.000000   \n",
       "\n",
       "             00WIND         06LAT         06LON        06WIND         12LAT  \\\n",
       "count  45293.000000  45293.000000  45293.000000  45293.000000  45293.000000   \n",
       "mean      62.021063     19.506798    132.481476     62.087077     19.018631   \n",
       "std       31.469743      7.243189     18.568924     31.423058      7.016464   \n",
       "min       10.000000      1.300000   -179.899994     10.000000      1.300000   \n",
       "25%       35.000000     14.200000    122.400002     35.000000     13.900000   \n",
       "50%       55.000000     18.799999    131.600006     55.000000     18.400000   \n",
       "75%       80.000000     24.100000    142.699997     80.000000     23.500000   \n",
       "max      185.000000     54.500000    180.000000    185.000000     53.500000   \n",
       "\n",
       "              12LON        12WIND         18LAT         18LON        18WIND  \\\n",
       "count  45293.000000  45293.000000  45293.000000  45293.000000  45293.000000   \n",
       "mean     132.967087     61.773122     18.551769    133.451675     61.072020   \n",
       "std       17.948254     31.615497      6.824604     17.685791     31.978523   \n",
       "min     -179.899994     10.000000      1.300000   -179.899994     10.000000   \n",
       "25%      123.000000     35.000000     13.600000    123.500000     35.000000   \n",
       "50%      132.000000     55.000000     18.000000    132.399994     55.000000   \n",
       "75%      143.000000     80.000000     22.900000    143.399994     80.000000   \n",
       "max      180.000000    185.000000     52.000000    180.000000    185.000000   \n",
       "\n",
       "              24LAT         24LON        24WIND  \n",
       "count  45293.000000  45293.000000  45293.000000  \n",
       "mean      18.104473    133.910690     60.020864  \n",
       "std        6.662520     17.910883     32.433757  \n",
       "min        1.300000   -180.000000     10.000000  \n",
       "25%       13.200000    124.000000     35.000000  \n",
       "50%       17.600000    132.800003     55.000000  \n",
       "75%       22.299999    143.899994     80.000000  \n",
       "max       50.500000    180.000000    185.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare dataset for model to read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "TRAIN_RATIO = 0.875\n",
    "NUM_EPOCHS = 3\n",
    "LR = 0.001\n",
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test-dev-train split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def separateDataset(dataset, train_ratio):\n",
    "    '''\n",
    "    Takes in a dataset (pandas df) and a ratio value, returns a dictionary containing the separated dataset.\n",
    "    Key \"train\" = train set, \"dev\" = dev set (size = train ratio * (sizeof input df - test set)), \"test\" = test set (size = train ratio * sizeof input df)\n",
    "    '''\n",
    "    train_dev_set, test_set = train_test_split(dataset, train_size=train_ratio)\n",
    "    train_set, dev_set = train_test_split(train_dev_set, train_size=0.8)\n",
    "    print(\"Training set size: {0}; Dev set size: {1}; Testing set size: {2}\".format(len(train_set), len(dev_set), len(test_set)))\n",
    "    return { \"train\": train_set, \"dev\": dev_set, \"test\": test_set }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Dataset class to feed into the model\n",
    "class BaselineDataset(Dataset):\n",
    "    '''\n",
    "    Custom dataset class to generate samples (X) and targets (Y) for the model.\n",
    "    '''\n",
    "    def __init__(self, dataframe):\n",
    "        self.df = dataframe.drop(['LOW_IMPACT', 'MID_IMPACT', 'BIG_IMPACT', 'DIRECT_STRIKE'], axis=1)\n",
    "        self.labels = np.asarray(dataframe.iloc[:,3:7]).astype(float)\n",
    "  \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        rowToUse = torch.tensor(self.df.iloc[idx]).float()\n",
    "        labelVector = torch.tensor(self.labels[idx]).float()\n",
    "        return (rowToUse, labelVector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 31704; Dev set size: 7927; Testing set size: 5662\n"
     ]
    }
   ],
   "source": [
    "splitDataset = separateDataset(dataset, TRAIN_RATIO)\n",
    "\n",
    "train_set = BaselineDataset(splitDataset[\"train\"])\n",
    "dev_set = BaselineDataset(splitDataset[\"dev\"])\n",
    "test_set = BaselineDataset(splitDataset[\"test\"])\n",
    "\n",
    "train_dl = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "dev_dl = DataLoader(dev_set, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "test_dl = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class BaselineMLP(nn.Module):\n",
    "    '''\n",
    "    The MLP model is defined here.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super(BaselineMLP, self).__init__()\n",
    "        \n",
    "        # input shape: (batch_size, 18)\n",
    "        # output shape: (batch_size, 4)\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(18, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 4), \n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Procedures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import torchmetrics\n",
    "\n",
    "# calculate accuracies and such\n",
    "def accuracy(output, target):\n",
    "    '''\n",
    "    Attempts to calculate accuracy and f1-score from the given outputs and targets (both on GPU).\n",
    "    '''\n",
    "    with torch.no_grad():\n",
    "        #batch_size = output.size(0)\n",
    "        \n",
    "        target = target.cpu()\n",
    "        preds = torch.round(output).cpu()\n",
    "        acc = accuracy_score(target, preds)\n",
    "        # acc = torchmetrics.functional.accuracy(preds, target.int(), num_classes=2, threshold=0.5, multiclass=True)        \n",
    "        f1 = f1_score(target, preds, average=None, zero_division=0)\n",
    "    \n",
    "    return acc, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train for one epoch\n",
    "\n",
    "def train_model_for_one_epoch(model, train_dl, criterion, optimizer):\n",
    "    '''The procedure to train the model for one epoch using the training set dataloader, loss function (criterion) and optimizer supplied'''\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    running_f1 = np.array([0.0, 0.0, 0.0, 0.0])\n",
    "        \n",
    "    for i, (inputs, targets) in enumerate(train_dl):\n",
    "        inputs = inputs.cuda()\n",
    "        targets = targets.cuda()\n",
    "        \n",
    "        # training steps\n",
    "        optimizer.zero_grad()\n",
    "        y = model(inputs)\n",
    "        loss = criterion(y, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # evaluate accuracy during training\n",
    "        acc, f1 = accuracy(y, targets)\n",
    "        \n",
    "        # book-keeping: average this epoch\n",
    "        running_loss += loss.item()\n",
    "        running_acc += acc\n",
    "        running_f1 += f1\n",
    "    \n",
    "    average_loss = running_loss/len(train_set)\n",
    "    average_acc = running_acc/len(train_set)\n",
    "    average_f1 = np.divide(running_f1, len(train_set))\n",
    "    \n",
    "    return average_acc, average_f1, average_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate on dev set\n",
    "\n",
    "def evaluate(model, dev_dl, criterion):\n",
    "    '''The procedure to evaluate the given model on the specified dev set (dataloader) using the supplied criterion (loss/objective)'''\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    running_f1 = np.array([0.0, 0.0, 0.0, 0.0])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, targets) in enumerate(dev_dl):\n",
    "            inputs = inputs.cuda()\n",
    "            targets = targets.cuda()\n",
    "            \n",
    "            y = model(inputs)\n",
    "            loss = criterion(y, targets)\n",
    "            \n",
    "            acc, f1 = accuracy(y, targets)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            running_acc += acc\n",
    "            running_f1 += f1\n",
    "            \n",
    "    return running_acc/len(dev_set), np.divide(running_f1, len(dev_set)), running_loss/len(dev_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main training loop\n",
    "from torch.optim import Adam, SGD\n",
    "import time\n",
    "\n",
    "def main_training_loop(model, train_dl, dev_dl):\n",
    "    '''Main training procedure, trains the model for some number of epochs, evaluating it at the end of each one'''\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = Adam(model.parameters(), lr=LR)\n",
    "    #optimizer = SGD(model.parameters(), lr=LR)\n",
    "    \n",
    "    train_acc_history = []\n",
    "    train_loss_history = []\n",
    "    dev_acc_history = []\n",
    "    dev_loss_history = []\n",
    "    \n",
    "    model.cuda()\n",
    "        \n",
    "    start_time = time.time()\n",
    "    print(\"Main training loop is starting.\")\n",
    "    \n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        epoch_start = time.time()\n",
    "        \n",
    "        train_acc, train_f1, train_loss = train_model_for_one_epoch(model, train_dl, criterion, optimizer)\n",
    "        train_acc_history.append(train_acc)\n",
    "        train_loss_history.append(train_loss)\n",
    "        \n",
    "        dev_acc, dev_f1, dev_loss = evaluate(model, dev_dl, criterion)\n",
    "        dev_acc_history.append(dev_acc)\n",
    "        dev_loss_history.append(dev_loss)\n",
    "        \n",
    "        epoch_time = time.time() - epoch_start\n",
    "        \n",
    "        if epoch % 1 == 0:\n",
    "            print(\"Progress: {0}/{1} epochs, train acc = {2:.5f}, dev acc = {3:.5f}, train loss = {4:.5f}, epoch time = {5:.2f}s\".format(epoch+1, NUM_EPOCHS, train_acc, dev_acc, train_loss, epoch_time))\n",
    "\n",
    "    training_time = time.time() - start_time\n",
    "    print(\"Training has completed. Time elapsed = {0}s\".format(training_time))\n",
    "    \n",
    "    training_history = { 'loss': train_loss_history, 'acc': train_acc_history }\n",
    "    validate_history = { 'loss': dev_loss_history, 'acc': dev_acc_history }\n",
    "    \n",
    "    return training_history, validate_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing on test set\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "def test_model(model, test_dl):\n",
    "    '''Tests the model on the test set via the dataloader'''\n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    running_f1 = np.array([0.0, 0.0, 0.0, 0.0])\n",
    "    running_precision = np.array([0.0, 0.0, 0.0, 0.0])\n",
    "    running_recall = np.array([0.0, 0.0, 0.0, 0.0])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, targets) in enumerate(test_dl):\n",
    "            inputs = inputs.cuda()\n",
    "            targets = targets.cuda()\n",
    "            \n",
    "            y = model(inputs)\n",
    "            loss = criterion(y, targets)\n",
    "            \n",
    "            acc, f1 = accuracy(y, targets)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            running_acc += acc\n",
    "            running_f1 += f1\n",
    "            \n",
    "            y = torch.round(y).cpu()\n",
    "            targets = targets.cpu()\n",
    "            running_precision += precision_score(targets, y, average=None, zero_division=0)\n",
    "            running_recall += recall_score(targets, y, average=None, zero_division=0)            \n",
    "            \n",
    "    final_avg_acc = running_acc/len(test_set)\n",
    "    final_avg_loss = running_loss/len(test_set)\n",
    "    final_avg_f1 = np.divide(running_f1, len(test_set))\n",
    "    final_avg_precision = np.divide(running_precision, len(test_set))\n",
    "    final_avg_recall = np.divide(running_recall, len(test_set))\n",
    "    \n",
    "    return {'acc': final_avg_acc, 'f1': final_avg_f1, 'loss': final_avg_loss, 'precision': final_avg_precision, 'recall': final_avg_recall}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ Main training and evaluation procedure ===============\n",
      "Main training loop is starting.\n",
      "Progress: 1/3 epochs, train acc = 0.00338, dev acc = 0.00334, train loss = 0.00079, epoch time = 12.50s\n",
      "Progress: 2/3 epochs, train acc = 0.00344, dev acc = 0.00334, train loss = 0.00068, epoch time = 12.26s\n",
      "Progress: 3/3 epochs, train acc = 0.00344, dev acc = 0.00334, train loss = 0.00065, epoch time = 11.30s\n",
      "Training has completed. Time elapsed = 36.05869913101196s\n",
      "{'acc': 0.0034315944012716353, 'f1': array([0., 0., 0., 0.]), 'loss': 0.0006630018337671515, 'precision': array([0., 0., 0., 0.]), 'recall': array([0., 0., 0., 0.])}\n"
     ]
    }
   ],
   "source": [
    "print(\"================ Main training and evaluation procedure ===============\")\n",
    "model = BaselineMLP()\n",
    "training_history, validate_history = main_training_loop(model, train_dl, dev_dl)\n",
    "results = test_model(model, test_dl)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving training results to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ Saving results to file ===============\n"
     ]
    }
   ],
   "source": [
    "# save model as checkpoint\n",
    "print(\"================ Saving results to file ===============\")\n",
    "\n",
    "from datetime import datetime\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "}, \"./models/baseline_model_{0}.pt\".format(str(datetime.now().strftime(\"%Y-%m-%d %H:%M\"))))\n",
    "\n",
    "# save histories to file\n",
    "df = pd.DataFrame.from_dict(training_history)\n",
    "df.to_csv(\"./models/baseline_model_{0}_training.csv\".format(str(datetime.now().strftime(\"%Y-%m-%d %H:%M\"))))\n",
    "df = pd.DataFrame.from_dict(validate_history)\n",
    "df.to_csv(\"./models/baseline_model_{0}_validate.csv\".format(str(datetime.now().strftime(\"%Y-%m-%d %H:%M\"))))\n",
    "\n",
    "# save scores to file\n",
    "array_like_scores = { key: value for key, value in results.items() if key in [\"f1\", \"precision\", \"recall\"] }\n",
    "df = pd.DataFrame.from_dict(array_like_scores)\n",
    "df.to_csv(\"./models/baseline_model_{0}_array_scores.csv\".format(str(datetime.now().strftime(\"%Y-%m-%d %H:%M\"))))\n",
    "general_scores = { key: [value] for key, value in results.items() if key in [\"acc\", \"loss\"] }\n",
    "df = pd.DataFrame.from_dict(general_scores)\n",
    "df.to_csv(\"./models/baseline_model_{0}_general_scores.csv\".format(str(datetime.now().strftime(\"%Y-%m-%d %H:%M\"))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
