{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8ab67a4",
   "metadata": {},
   "source": [
    "# Example Operational Forecast\n",
    "\n",
    "The sample shown is Typhoon Kompasu (2021), date 10 October 2021. In the end, there was no T1, but a T3 and a T8 in by 12 October.\n",
    "\n",
    "System requirements:\n",
    "- Two Anaconda (recommended) environments, one for dynamical data preprocessing (Python 2 + PyNIO) and another for the models (Python 3)  \n",
    "  - This env requires numpy, pandas, scipy, pygam, sktime, xgboost, sklearn, geopy, geographiclib.\n",
    "- At least 2.5GB of free disk space to hold the models, extra 500MB recommended to hold dynamical data\n",
    "- 4+ CPU cores and preferably 8+ GB RAM (when the models are loaded, around 2.5GB is used), also a GPU may be needed for xgboost\n",
    "\n",
    "Steps:\n",
    "1. Make sure this is the correct environment - running Python 3 and has numpy, pandas, scipy, pygam, sktime, xgboost and sklearn available   \n",
    "2. Make sure you have preprocessed the correct dynamical data and placed them under `./data` folder  \n",
    "3. Execute the following cells until you encounter markdown  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "288cfef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07ef61e",
   "metadata": {},
   "source": [
    "Step 4: Enter model paths and execute the cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d732c2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The folder housing all the models we will need\n",
    "model_folder = \"./../models/\"\n",
    "\n",
    "# The exact file names of the ensemble voting estimator, folder excluded\n",
    "ensemble_name = 'ensemble_7member_ridge_2022-04-17 20-14.skl'\n",
    "\n",
    "# The exact file names of the ensemble member models, folder excluded\n",
    "xgb_clf_name = 'experimental_model_gscv_xgb_clf_2022-04-12 19-13.skl'\n",
    "xgb_regr_name = 'experimental_model_gscv_xgb_regr_2022-04-16 20-15.skl'\n",
    "extra_trees_clf_name = 'experimental_model_gscv_extra_trees_clf_2022-04-12 19-18.skl'\n",
    "extra_trees_regr_name = 'experimental_model_gscv_extra_trees_regr_2022-04-16 17-15.skl'\n",
    "mlp_clf_name = 'experimental_model_mlpclf_2022-04-12 21-18.skl'\n",
    "tsfs_clf_name = 'experimental_model_calibrated_gscv_tsfs_clf_2022-04-12 20-11.skl'\n",
    "gam_name = 'experimental_model_gam_tsnv_2022-04-14 18-20.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3e5ea33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load models\n",
    "from sklearn.ensemble import ExtraTreesClassifier, ExtraTreesRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.multioutput import MultiOutputClassifier, MultiOutputRegressor\n",
    "from sktime.classification.interval_based import TimeSeriesForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import pickle as pk\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif #, SelectFromModel\n",
    "from functools import partial\n",
    "from pygam import LinearGAM, PoissonGAM\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "xgb_clf = joblib.load(model_folder + xgb_clf_name)\n",
    "xgb_regr = joblib.load(model_folder + xgb_regr_name)\n",
    "extra_trees_gscv_clf = joblib.load(model_folder + extra_trees_clf_name)\n",
    "extra_trees_gscv_regr = joblib.load(model_folder + extra_trees_regr_name)\n",
    "mlp_clf = joblib.load(model_folder + mlp_clf_name)\n",
    "tsfs_calibrated_clf = joblib.load(model_folder + tsfs_clf_name)\n",
    "\n",
    "file = open(model_folder + gam_name, \"rb\") \n",
    "gam = pk.load(file)\n",
    "file.close()\n",
    "\n",
    "file = open(model_folder + ensemble_name, \"rb\")\n",
    "ensembles = pk.load(file)\n",
    "file.close()\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf85086a",
   "metadata": {},
   "source": [
    "Step 5: Enter TC data particulars\n",
    "\n",
    "Much of the information you'll need can be sourced from [RAMMB](https://rammb-data.cira.colostate.edu/tc_realtime/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ec65d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current date and hour (preferably at 00, 06, 12 or 18)\n",
    "YY00, MM00, DD00, HH00 = 2021, 10, 11, 18 \n",
    "\n",
    "# HKO warning signal status over the last 24 hours\n",
    "# MI: true if T1, LI: true if T3, SI: true if T8 or plus\n",
    "# DS: true if TC in HKO 100 radius\n",
    "MI_STATUS00, LI_STATUS00, SI_STATUS00, DS_STATUS00 = False, False, False, False\n",
    "MI_STATUS06, LI_STATUS06, SI_STATUS06, DS_STATUS06 = False, False, False, False\n",
    "MI_STATUS12, LI_STATUS12, SI_STATUS12, DS_STATUS12 = False, False, False, False\n",
    "MI_STATUS18, LI_STATUS18, SI_STATUS18, DS_STATUS18 = False, False, False, False\n",
    "MI_STATUS24, LI_STATUS24, SI_STATUS24, DS_STATUS24 = False, False, False, False\n",
    "\n",
    "# TC position and intensity over last 24 hours\n",
    "LAT00, LON00, VMAX00 = 18.8, 120.5, 55\n",
    "LAT06, LON06, VMAX06 = 18.9, 121.6, 55\n",
    "LAT12, LON12, VMAX12 = 18.9, 123.1, 50\n",
    "LAT18, LON18, VMAX18 = 18.5, 124.2, 50\n",
    "LAT24, LON24, VMAX24 = 18.8, 124.9, 45\n",
    "LAT30, LON30 = 18.4, 126.6 # needed to estimate speed and heading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef57724",
   "metadata": {},
   "source": [
    "Step 6: Load dynamical variables values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0d802ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def read_csv_to_dict(filename):\n",
    "    '''Takes in a filename to a CSV file (without extension) and returns its content as a dictionary (str -> float)'''\n",
    "    with open(filename, 'r') as infile:\n",
    "        reader = csv.reader(infile)\n",
    "        mydict = {rows[0]:float(rows[1]) for rows in reader}\n",
    "    return mydict\n",
    "\n",
    "easm = read_csv_to_dict(\"./easm_indices.csv\")\n",
    "hi_humid = read_csv_to_dict(\"./hi_humid.csv\")\n",
    "hk_u_winds = read_csv_to_dict(\"./hk_u_winds.csv\")\n",
    "lo_humid = read_csv_to_dict(\"./lo_humid.csv\")\n",
    "hk_v_winds = read_csv_to_dict(\"./hk_v_winds.csv\")\n",
    "mlvws = read_csv_to_dict(\"./mlvws.csv\") \n",
    "pott = read_csv_to_dict(\"./pott.csv\")\n",
    "temp_surface = read_csv_to_dict(\"./temp_surface.csv\")\n",
    "temp200 = read_csv_to_dict(\"./temp200.csv\")\n",
    "u200 = read_csv_to_dict(\"./u200.csv\")\n",
    "u500 = read_csv_to_dict(\"./u500.csv\")\n",
    "ulvws = read_csv_to_dict(\"./ulvws.csv\")\n",
    "v500 = read_csv_to_dict(\"./v500.csv\")\n",
    "vort850 = read_csv_to_dict(\"./vort850.csv\")\n",
    "westerly = read_csv_to_dict(\"./westerly_indices.csv\")\n",
    "wnpsh_area = read_csv_to_dict(\"./wnpsh_area_indices.csv\")\n",
    "wnpsh_intensity = read_csv_to_dict(\"./wnpsh_intensity_indices.csv\")\n",
    "wnpsh_extension = read_csv_to_dict(\"./wnpsh_extension_indices.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2270e64",
   "metadata": {},
   "source": [
    "Step 7: Finish input data pre-processing, execute the cells below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3315086d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149\n"
     ]
    }
   ],
   "source": [
    "# converting to arrays to ease processing\n",
    "# the format before was for easier fill in\n",
    "mi = [MI_STATUS00,MI_STATUS06,MI_STATUS12,MI_STATUS18,MI_STATUS24]\n",
    "li = [LI_STATUS00,LI_STATUS06,LI_STATUS12,LI_STATUS18,LI_STATUS24]\n",
    "si = [SI_STATUS00,SI_STATUS06,SI_STATUS12,SI_STATUS18,SI_STATUS24]\n",
    "ds = [DS_STATUS00,DS_STATUS06,DS_STATUS12,DS_STATUS18,DS_STATUS24]\n",
    "lat = [LAT00,LAT06,LAT12,LAT18,LAT24,LAT30]\n",
    "lon = [LON00,LON06,LON12,LON18,LON24,LON30]\n",
    "vmax = [VMAX00,VMAX06,VMAX12,VMAX18,VMAX24]\n",
    "\n",
    "# helper functions\n",
    "from geographiclib.geodesic import Geodesic\n",
    "import geopy.distance\n",
    "\n",
    "def find_azimuth(lat0: float, long0: float, lat1: float, long1: float):\n",
    "    '''Takes in two pairs of latitudes and longitudes, returns latter's forward azimuth from former.'''\n",
    "    azimuth = Geodesic.WGS84.Inverse(lat0, long0, lat1, long1)['azi1']\n",
    "    # the given azimuth is in [-180, 180], I prefer [0, 360] instead\n",
    "    return (azimuth + 360.0) % 360.0\n",
    "\n",
    "def azimuth_to_HK(lat: float, long: float):\n",
    "    '''Takes in a latitude and a longitude, returns its forward azimuth from Hong Kong.'''\n",
    "    # constants\n",
    "    hko_lat = 22.302219\n",
    "    hko_long = 114.174637\n",
    "    azimuth = find_azimuth(hko_lat, hko_long, lat, long)\n",
    "    return azimuth\n",
    "\n",
    "def estimate_speed(lat0, long0, lat1, long1):\n",
    "    '''Takes in two pairs of latitudes and longitudes, returns the speed (knots) needed to cover the distance between them in 6 hours.'''\n",
    "    distance_travelled = geopy.distance.distance((lat0, long0), (lat1, long1)).km * 1.852\n",
    "    return distance_travelled / 6\n",
    "\n",
    "# columns of the data sample\n",
    "columns = []\n",
    "for i in range(0, 24+6, 6):\n",
    "    columns.append('MM{0:02d}'.format(i))\n",
    "    columns.append('DD{0:02d}'.format(i))\n",
    "\n",
    "    columns.append('MI_STATUS{0:02d}'.format(i))\n",
    "    columns.append('LI_STATUS{0:02d}'.format(i))\n",
    "    columns.append('SI_STATUS{0:02d}'.format(i))\n",
    "    columns.append('DS_STATUS{0:02d}'.format(i))\n",
    "\n",
    "    columns.append('DIST{0:02d}'.format(i))\n",
    "    columns.append('AZM{0:02d}'.format(i))\n",
    "    columns.append('SPEED{0:02d}'.format(i))\n",
    "    columns.append('DIR{0:02d}'.format(i))\n",
    "    columns.append('VMAX{0:02d}'.format(i))\n",
    "\n",
    "    if i != 24:\n",
    "        columns.append('DVMAX{0:02d}'.format(i))\n",
    "        \n",
    "    columns.append('ULVWS{0:02d}'.format(i))\n",
    "    columns.append('MLVWS{0:02d}'.format(i))\n",
    "    \n",
    "    columns.append('HI_HUMID{0:02d}'.format(i))\n",
    "    columns.append('LO_HUMID{0:02d}'.format(i))\n",
    "    \n",
    "    columns.append('STEMP{0:02d}'.format(i))\n",
    "    columns.append('UTEMP{0:02d}'.format(i))\n",
    "    \n",
    "    columns.append('U_HK{0:02d}'.format(i))\n",
    "    columns.append('V_HK{0:02d}'.format(i))    \n",
    "    columns.append('U200{0:02d}'.format(i))\n",
    "    columns.append('U500{0:02d}'.format(i))\n",
    "    columns.append('V500{0:02d}'.format(i))    \n",
    "    columns.append('EASM{0:02d}'.format(i))\n",
    "    \n",
    "    columns.append('VORT{0:02d}'.format(i))\n",
    "    \n",
    "    columns.append('WESTERLY{0:02d}'.format(i))\n",
    "    columns.append('SH_AREA{0:02d}'.format(i))\n",
    "    columns.append('SH_INT{0:02d}'.format(i))\n",
    "    columns.append('SH_EXT{0:02d}'.format(i))\n",
    "    \n",
    "    columns.append('POTT{0:02d}'.format(i))    \n",
    "print(len(columns)) # this should be 149"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8348de9f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This number should be 149: 149\n",
      "Input data:\n",
      "   MM00  DD00  MI_STATUS00  LI_STATUS00  SI_STATUS00  DS_STATUS00      DIST00  \\\n",
      "0    10    11        False        False        False        False  764.957672   \n",
      "\n",
      "        AZM00  SPEED00  DIR00  ...    U20024    U50024    V50024     EASM24  \\\n",
      "0  119.307465       35    264  ...  8.959722  8.959722  1.929861  43.924152   \n",
      "\n",
      "      VORT24  WESTERLY24  SH_AREA24  SH_INT24  SH_EXT24     POTT24  \n",
      "0  37.749996   469.44098          0       0.0         0  296.97998  \n",
      "\n",
      "[1 rows x 149 columns]\n"
     ]
    }
   ],
   "source": [
    "# processing\n",
    "from datetime import datetime, timedelta\n",
    "from numpy import dtype\n",
    "\n",
    "data_X = []\n",
    "\n",
    "time_stamp = datetime(YY00, MM00, DD00, HH00)\n",
    "for i in range(5):\n",
    "    # time info\n",
    "    data_X.append(time_stamp.month)\n",
    "    data_X.append(time_stamp.day)\n",
    "    \n",
    "    # endogenous variables\n",
    "    data_X.append(mi[i])\n",
    "    data_X.append(li[i])\n",
    "    data_X.append(si[i])\n",
    "    data_X.append(ds[i])\n",
    "    \n",
    "    # calculate distance, azimuth, speed and direction\n",
    "    temp = geopy.distance.distance((22.302219, 114.174637), (lat[i], lon[i]))\n",
    "    data_X.append(temp.km) # dist\n",
    "    data_X.append(azimuth_to_HK(lat[i], lon[i])) # azm\n",
    "    data_X.append(estimate_speed(lat[i+1], lon[i+1], lat[i], lon[i])) # speed\n",
    "    data_X.append(find_azimuth(lat[i+1], lon[i+1], lat[i], lon[i])) # dir\n",
    "    \n",
    "    # vmax and dvmax\n",
    "    data_X.append(vmax[i])\n",
    "    if i != 4:\n",
    "        data_X.append(vmax[i] - vmax[i+1])\n",
    "    \n",
    "    # dynamical variables\n",
    "    key = time_stamp.strftime(\"%Y%m%d_%H_%M\")\n",
    "    \n",
    "    data_X.append(ulvws[key])\n",
    "    data_X.append(mlvws[key])\n",
    "    data_X.append(hi_humid[key])\n",
    "    data_X.append(lo_humid[key])\n",
    "    data_X.append(temp_surface[key])\n",
    "    data_X.append(temp200[key])\n",
    "    data_X.append(hk_u_winds[key])\n",
    "    data_X.append(hk_v_winds[key])\n",
    "    data_X.append(u200[key])\n",
    "    data_X.append(u500[key])\n",
    "    data_X.append(v500[key])\n",
    "    data_X.append(easm[key])\n",
    "    data_X.append(vort850[key] * 1e6)\n",
    "    data_X.append(westerly[key])\n",
    "    data_X.append(int(wnpsh_area[key]))\n",
    "    data_X.append(wnpsh_intensity[key])\n",
    "    data_X.append(int(wnpsh_extension[key]))\n",
    "    data_X.append(pott[key])\n",
    "    \n",
    "    time_stamp -= timedelta(hours=6)\n",
    "    \n",
    "data_X = pd.DataFrame(data_X)    \n",
    "print(\"This number should be 149:\", len(data_X))\n",
    "\n",
    "# convert to 1 sample, 149 cols\n",
    "data_X = data_X.transpose()\n",
    "\n",
    "# fix types, else XGBoost will complain\n",
    "types = [\n",
    "    dtype('int32'), dtype('int32'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), \n",
    "    dtype('float64'), dtype('float64'), dtype('int32'), dtype('int32'), dtype('int32'), \n",
    "    dtype('int32'), dtype('float64'), dtype('float64'), dtype('float64'), dtype('float64'), \n",
    "    dtype('float64'), dtype('float64'), dtype('float64'), dtype('float64'), dtype('float64'),\n",
    "    dtype('float64'), dtype('float64'), dtype('float64'), dtype('float64'), dtype('float64'), \n",
    "    dtype('int64'), dtype('float64'), dtype('int64'), dtype('float64'), dtype('int32'), \n",
    "    dtype('int32'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), \n",
    "    dtype('float64'), dtype('float64'), dtype('int32'), dtype('int32'), dtype('int32'), \n",
    "    dtype('int32'), dtype('float64'), dtype('float64'), dtype('float64'), dtype('float64'), \n",
    "    dtype('float64'), dtype('float64'), dtype('float64'), dtype('float64'), dtype('float64'), \n",
    "    dtype('float64'), dtype('float64'), dtype('float64'), dtype('float64'), dtype('float64'), \n",
    "    dtype('int64'), dtype('float64'), dtype('int64'), dtype('float64'), dtype('int32'), \n",
    "    dtype('int32'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('float64'),\n",
    "    dtype('float64'), dtype('int32'), dtype('int32'), dtype('int32'), dtype('int32'), dtype('float64'),\n",
    "    dtype('float64'), dtype('float64'), dtype('float64'), dtype('float64'), dtype('float64'), dtype('float64'),\n",
    "    dtype('float64'), dtype('float64'), dtype('float64'), dtype('float64'), dtype('float64'), dtype('float64')\n",
    "    , dtype('float64'), dtype('int64'), dtype('float64'), dtype('int64'), dtype('float64'), dtype('int32'), \n",
    "    dtype('int32'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('bool'), dtype('float64'), dtype('float64'), \n",
    "    dtype('int32'), dtype('int32'), dtype('int32'), dtype('int32'), dtype('float64'), dtype('float64'), \n",
    "    dtype('float64'), dtype('float64'), dtype('float64'), dtype('float64'), dtype('float64'), dtype('float64'), \n",
    "    dtype('float64'), dtype('float64'), dtype('float64'), dtype('float64'), dtype('float64'), dtype('float64'), \n",
    "    dtype('int64'), dtype('float64'), dtype('int64'), dtype('float64'), dtype('int32'), dtype('int32'), dtype('bool'),\n",
    "    dtype('bool'), dtype('bool'), dtype('bool'), dtype('float64'), dtype('float64'), dtype('int32'), dtype('int32'),\n",
    "    dtype('int32'), dtype('float64'), dtype('float64'), dtype('float64'), dtype('float64'), dtype('float64'), dtype('float64'),\n",
    "    dtype('float64'), dtype('float64'), dtype('float64'), dtype('float64'), dtype('float64'), dtype('float64'),\n",
    "    dtype('float64'), dtype('float64'), dtype('int64'), dtype('float64'), dtype('int64'), dtype('float64')\n",
    "]\n",
    "data_X = data_X.astype(dict(zip(range(len(types)), types)))\n",
    "\n",
    "data_X = data_X.set_axis(columns, axis=1, inplace=False)\n",
    "print(\"Input data:\")\n",
    "print(data_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "45839a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1 entries, 0 to 0\n",
      "Columns: 149 entries, MM00 to POTT24\n",
      "dtypes: bool(20), float64(90), int32(29), int64(10)\n",
      "memory usage: 1.0 KB\n"
     ]
    }
   ],
   "source": [
    "data_X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a10b4156",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropping ['DVMAX00', 'DVMAX06', 'DVMAX12', 'DVMAX18']\n",
      "Completed\n",
      "Before transform: (1, 29, 5)\n",
      "After transform: (1, 1)\n",
      "Each element is: (145,)\n"
     ]
    }
   ],
   "source": [
    "# for sktime\n",
    "from sktime.transformations.panel.compose import ColumnConcatenator\n",
    "\n",
    "def convert_X(dataset_X):\n",
    "    '''Takes in a (n_samples, n_features) Pandas dataframe and returns it in shape (n_samples, n_features, time_series_length)'''\n",
    "    to_drop = [\"DVMAX{0:02d}\".format(i) for i in range(0, 24, 6)]\n",
    "    print(\"dropping\", to_drop)\n",
    "    dataset_X = dataset_X.drop(to_drop, axis=1)\n",
    "    \n",
    "    processed_samples = 0\n",
    "    new_dataset = []\n",
    "    for index, row in dataset_X.iterrows():\n",
    "        new_row = []\n",
    "\n",
    "        # obtain time series for each feature        \n",
    "        for i in range(29):\n",
    "            feature_name = dataset_X.columns[i][:-2]\n",
    "            feature_series = []\n",
    "            for j in range(0, 24+6, 6):        \n",
    "                feature_series.append(row.loc[\"{0}{1:02d}\".format(feature_name, j)]) # access by column name\n",
    "            feature_series.reverse() # newest data come last\n",
    "            feature_series = pd.Series(data=feature_series) # correct type for each cell\n",
    "            new_row.append(feature_series)\n",
    "\n",
    "        # new_row = pd.Series(data=new_row, index=new_features)\n",
    "        new_dataset.append(new_row)\n",
    "        processed_samples += 1\n",
    "\n",
    "        if processed_samples % 1000 == 0:\n",
    "            print(\"Finished concatenating {0}/{1} samples...\".format(processed_samples, dataset_X.shape[0]))\n",
    "            \n",
    "    # convert types back\n",
    "    # converted_X = pd.DataFrame(new_dataset, columns=new_features)\n",
    "    converted_X = np.array(new_dataset)\n",
    "    print(\"Completed\")\n",
    "    return converted_X\n",
    "    \n",
    "concat_data_X = convert_X(data_X)\n",
    "print(\"Before transform:\", concat_data_X.shape)\n",
    "concat_data_X = ColumnConcatenator().fit_transform(concat_data_X)\n",
    "print(\"After transform:\", concat_data_X.shape)\n",
    "print(\"Each element is:\", concat_data_X.iloc[0].iloc[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825cdbb2",
   "metadata": {},
   "source": [
    "Step 8: The ensemble members generate their predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c26bec2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/userhome/cs/u3556490/anaconda3/envs/test/lib/python3.9/site-packages/xgboost/data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "/userhome/cs/u3556490/anaconda3/envs/test/lib/python3.9/site-packages/xgboost/data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "/userhome/cs/u3556490/anaconda3/envs/test/lib/python3.9/site-packages/xgboost/data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "/userhome/cs/u3556490/anaconda3/envs/test/lib/python3.9/site-packages/xgboost/data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "/userhome/cs/u3556490/anaconda3/envs/test/lib/python3.9/site-packages/sktime/datatypes/_series/_check.py:43: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  VALID_INDEX_TYPES = (pd.Int64Index, pd.RangeIndex, pd.PeriodIndex, pd.DatetimeIndex)\n",
      "/userhome/cs/u3556490/anaconda3/envs/test/lib/python3.9/site-packages/sktime/datatypes/_series/_check.py:43: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  VALID_INDEX_TYPES = (pd.Int64Index, pd.RangeIndex, pd.PeriodIndex, pd.DatetimeIndex)\n",
      "/userhome/cs/u3556490/anaconda3/envs/test/lib/python3.9/site-packages/sktime/datatypes/_series/_check.py:43: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  VALID_INDEX_TYPES = (pd.Int64Index, pd.RangeIndex, pd.PeriodIndex, pd.DatetimeIndex)\n",
      "/userhome/cs/u3556490/anaconda3/envs/test/lib/python3.9/site-packages/sktime/datatypes/_series/_check.py:43: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  VALID_INDEX_TYPES = (pd.Int64Index, pd.RangeIndex, pd.PeriodIndex, pd.DatetimeIndex)\n",
      "/userhome/cs/u3556490/anaconda3/envs/test/lib/python3.9/site-packages/sktime/datatypes/_hierarchical/_check.py:50: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  VALID_INDEX_TYPES = (pd.Int64Index, pd.RangeIndex, pd.PeriodIndex, pd.DatetimeIndex)\n",
      "/userhome/cs/u3556490/anaconda3/envs/test/lib/python3.9/site-packages/sktime/datatypes/_hierarchical/_check.py:51: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  VALID_MULTIINDEX_TYPES = (pd.Int64Index, pd.RangeIndex)\n",
      "/userhome/cs/u3556490/anaconda3/envs/test/lib/python3.9/site-packages/sktime/datatypes/_hierarchical/_check.py:50: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  VALID_INDEX_TYPES = (pd.Int64Index, pd.RangeIndex, pd.PeriodIndex, pd.DatetimeIndex)\n",
      "/userhome/cs/u3556490/anaconda3/envs/test/lib/python3.9/site-packages/sktime/datatypes/_hierarchical/_check.py:50: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  VALID_INDEX_TYPES = (pd.Int64Index, pd.RangeIndex, pd.PeriodIndex, pd.DatetimeIndex)\n",
      "/userhome/cs/u3556490/anaconda3/envs/test/lib/python3.9/site-packages/sktime/datatypes/_hierarchical/_check.py:51: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  VALID_MULTIINDEX_TYPES = (pd.Int64Index, pd.RangeIndex)\n",
      "/userhome/cs/u3556490/anaconda3/envs/test/lib/python3.9/site-packages/sktime/datatypes/_hierarchical/_check.py:50: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  VALID_INDEX_TYPES = (pd.Int64Index, pd.RangeIndex, pd.PeriodIndex, pd.DatetimeIndex)\n",
      "/userhome/cs/u3556490/anaconda3/envs/test/lib/python3.9/site-packages/sktime/datatypes/_hierarchical/_check.py:51: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  VALID_MULTIINDEX_TYPES = (pd.Int64Index, pd.RangeIndex)\n",
      "/userhome/cs/u3556490/anaconda3/envs/test/lib/python3.9/site-packages/sktime/datatypes/_hierarchical/_check.py:51: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  VALID_MULTIINDEX_TYPES = (pd.Int64Index, pd.RangeIndex)\n",
      "/userhome/cs/u3556490/anaconda3/envs/test/lib/python3.9/site-packages/sktime/datatypes/_panel/_check.py:48: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  VALID_INDEX_TYPES = (pd.Int64Index, pd.RangeIndex, pd.PeriodIndex, pd.DatetimeIndex)\n",
      "/userhome/cs/u3556490/anaconda3/envs/test/lib/python3.9/site-packages/sktime/datatypes/_panel/_check.py:49: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  VALID_MULTIINDEX_TYPES = (pd.Int64Index, pd.RangeIndex)\n",
      "/userhome/cs/u3556490/anaconda3/envs/test/lib/python3.9/site-packages/sktime/datatypes/_panel/_check.py:48: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  VALID_INDEX_TYPES = (pd.Int64Index, pd.RangeIndex, pd.PeriodIndex, pd.DatetimeIndex)\n",
      "/userhome/cs/u3556490/anaconda3/envs/test/lib/python3.9/site-packages/sktime/datatypes/_panel/_check.py:49: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  VALID_MULTIINDEX_TYPES = (pd.Int64Index, pd.RangeIndex)\n",
      "/userhome/cs/u3556490/anaconda3/envs/test/lib/python3.9/site-packages/sktime/datatypes/_panel/_check.py:48: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  VALID_INDEX_TYPES = (pd.Int64Index, pd.RangeIndex, pd.PeriodIndex, pd.DatetimeIndex)\n",
      "/userhome/cs/u3556490/anaconda3/envs/test/lib/python3.9/site-packages/sktime/datatypes/_panel/_check.py:49: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  VALID_MULTIINDEX_TYPES = (pd.Int64Index, pd.RangeIndex)\n",
      "/userhome/cs/u3556490/anaconda3/envs/test/lib/python3.9/site-packages/sktime/datatypes/_panel/_check.py:48: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  VALID_INDEX_TYPES = (pd.Int64Index, pd.RangeIndex, pd.PeriodIndex, pd.DatetimeIndex)\n",
      "/userhome/cs/u3556490/anaconda3/envs/test/lib/python3.9/site-packages/sktime/datatypes/_panel/_check.py:49: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  VALID_MULTIINDEX_TYPES = (pd.Int64Index, pd.RangeIndex)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictand 0 finished, predictions shape should look like (1,7): (1, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/userhome/cs/u3556490/anaconda3/envs/test/lib/python3.9/site-packages/xgboost/data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "/userhome/cs/u3556490/anaconda3/envs/test/lib/python3.9/site-packages/xgboost/data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "/userhome/cs/u3556490/anaconda3/envs/test/lib/python3.9/site-packages/xgboost/data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "/userhome/cs/u3556490/anaconda3/envs/test/lib/python3.9/site-packages/xgboost/data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictand 1 finished, predictions shape should look like (1,7): (1, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/userhome/cs/u3556490/anaconda3/envs/test/lib/python3.9/site-packages/xgboost/data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "/userhome/cs/u3556490/anaconda3/envs/test/lib/python3.9/site-packages/xgboost/data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "/userhome/cs/u3556490/anaconda3/envs/test/lib/python3.9/site-packages/xgboost/data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "/userhome/cs/u3556490/anaconda3/envs/test/lib/python3.9/site-packages/xgboost/data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictand 2 finished, predictions shape should look like (1,7): (1, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/userhome/cs/u3556490/anaconda3/envs/test/lib/python3.9/site-packages/xgboost/data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "/userhome/cs/u3556490/anaconda3/envs/test/lib/python3.9/site-packages/xgboost/data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "/userhome/cs/u3556490/anaconda3/envs/test/lib/python3.9/site-packages/xgboost/data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "/userhome/cs/u3556490/anaconda3/envs/test/lib/python3.9/site-packages/xgboost/data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictand 3 finished, predictions shape should look like (1,7): (1, 7)\n",
      "All done! Prediction shapes should look like (4,1,7): (4, 1, 7)\n"
     ]
    }
   ],
   "source": [
    "all_input_preds = []\n",
    "\n",
    "for i in range(4):\n",
    "    train_preds = []\n",
    "\n",
    "    proba = np.array(xgb_clf.predict_proba(data_X))[i,:,1]\n",
    "    train_preds.append(proba)\n",
    "    proba = np.array(xgb_regr.predict(data_X))[:,i]\n",
    "    train_preds.append(proba)\n",
    "    \n",
    "    proba = np.array(extra_trees_gscv_clf.predict_proba(data_X))[i,:,1]\n",
    "    train_preds.append(proba)\n",
    "    proba = np.array(extra_trees_gscv_regr.predict(data_X))[:,i]\n",
    "    train_preds.append(proba)\n",
    "    \n",
    "    train_preds.append(mlp_clf.predict_proba(data_X)[:,i])\n",
    "    \n",
    "    proba = np.array(tsfs_calibrated_clf.predict_proba(concat_data_X))[i,:,1]\n",
    "    train_preds.append(proba)\n",
    "    \n",
    "    in_data_X = gam[\"poly\"][i].transform(data_X.iloc[:,:(gam[\"input_feature_count\"][i])])\n",
    "    tr_data_X = gam[\"fs\"][i].transform(in_data_X)\n",
    "    preds = np.clip(gam[\"gam\"][i].predict(tr_data_X), 0, 1)\n",
    "    train_preds.append(preds)\n",
    "\n",
    "    train_preds = np.array(train_preds).T\n",
    "    print(\"Predictand {0} finished, predictions shape should look like (1,7): {1}\".format(i, train_preds.shape))\n",
    "    all_input_preds.append(train_preds)\n",
    "    \n",
    "all_input_preds = np.array(all_input_preds)\n",
    "print(\"All done! Prediction shapes should look like (4,1,7):\", all_input_preds.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c072734",
   "metadata": {},
   "source": [
    "Step 9: Ensemble makes final predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "edc55730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape should be (1,): (1,)\n",
      "The shape should be (1,): (1,)\n",
      "The shape should be (1,): (1,)\n",
      "The shape should be (1,): (1,)\n",
      "Raw probabilities: [0.58010094 0.19066854 0.05907501 0.01526025]\n"
     ]
    }
   ],
   "source": [
    "all_preds = []\n",
    "\n",
    "for i in range(4):\n",
    "    test_preds = ensembles[i].predict(all_input_preds[i,:,:])\n",
    "    print(\"The shape should be (1,):\", test_preds.shape)\n",
    "    all_preds.append(float(test_preds))\n",
    "    \n",
    "all_preds = np.clip(all_preds, 0, 1)\n",
    "print(\"Raw probabilities:\", all_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc1b530",
   "metadata": {},
   "source": [
    "Step 10: Look at the final report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fb3d0cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tropical cyclone impact level probability forecast\n",
      "Date/time of forecast: UTC 2021/10/11 18:00\n",
      "-----------------------------------------------------------------\n",
      "Probability of minimal impact (T1): 58.010%\n",
      "Probability of limited impact (T3): 19.067%\n",
      "Probability of substantial impact (T8 to T10): 5.908%\n",
      "Probability of direct strike (100 km radius of HKO): 1.526%\n",
      "-----------------------------------------------------------------\n",
      "The above forecast is valid for 72 hours.\n",
      "If any of the four probabilities are bigger than 40.49%, 37.43%, 39.51% and 27.89% respectively,\n",
      "then you can assume that the corresponding is more likely to happen than not.\n",
      "These figures are not official. Please consult the HKO for more reliable forecasts.\n"
     ]
    }
   ],
   "source": [
    "decision_thresholds = [0.40494, 0.37428, 0.39512, 0.27891]\n",
    "\n",
    "# show probabilities\n",
    "print(\"Tropical cyclone impact level probability forecast\")\n",
    "print(\"Date/time of forecast: UTC {0:04d}/{1:02d}/{2:02d} {3:02d}:00\".format(YY00,MM00,DD00,HH00))\n",
    "print(\"-----------------------------------------------------------------\")\n",
    "print(\"Probability of minimal impact (T1): {0:.3%}\".format(all_preds[0]))\n",
    "print(\"Probability of limited impact (T3): {0:.3%}\".format(all_preds[1]))\n",
    "print(\"Probability of substantial impact (T8 to T10): {0:.3%}\".format(all_preds[2]))\n",
    "print(\"Probability of direct strike (100 km radius of HKO): {0:.3%}\".format(all_preds[3]))\n",
    "print(\"-----------------------------------------------------------------\")\n",
    "print(\"The above forecast is valid for 72 hours.\")\n",
    "print(\"If any of the four probabilities are bigger than {0:.2%}, {1:.2%}, {2:.2%} and {3:.2%} respectively,\".format(\n",
    "    decision_thresholds[0], decision_thresholds[1], decision_thresholds[2], decision_thresholds[3]))\n",
    "print(\"then you can assume that the corresponding is more likely to happen than not.\")\n",
    "print(\"These figures are not official. Please consult the HKO for more reliable forecasts.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
